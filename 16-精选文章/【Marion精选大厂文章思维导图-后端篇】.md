# 【Marion精选大厂文章思维导图-后端篇】

## 阿里开发者

### 1. 性能测试PTS

- 产品简介

	- 什么是性能测试PTS

	  性能测试PTS（Performance Testing Service）是一款简单易用，具备强大的分布式压测能力的SaaS压测平台。 PTS可以模拟复杂的业务场景，并快速精准地调度不同规模的流量，同时提供压测过程中多维度的监控指标和日志记录。您无需准备资源，即可按需发起压测任务，监控压测指标，获取压测报告，进而能够高效率、全方位地验证业务站点的性能、容量和稳定性。
	  
	  PTS目标是将性能压测本身的工作持续简化，使您可以将更多的精力回归到关注业务和性能问题本身。在PTS平台上，您可以用较低的人力和资源成本，构造出最接近真实业务场景的复杂交互式流量，快速衡量系统的业务性能状况，为性能问题定位、容量配比、全链路压测的流量构造提供更好的帮助。进而提升用户体验，促进业务发展，最大程度实现企业的商业价值。
	  

		- 压测流程
		- 压测创建方式
		- 学习路径图

	- 功能特性

	  PTS提供场景编排、API调试、流量录制等功能，可快速创建业务压测脚本，同时100%兼容JMeter。通过百万并发、千万TPS流量发起能力以及流量地域定制功能，可精准模拟真实的用户访问模型，帮助业务快速提升系统性能和稳定性。
	  

	- 产品优势
	- 应用场景
	- 基本概念

		- 术语表
		- 并发虚拟用户、RPS、TPS的解读

			- 背景
			- 术语定义
			- VU和TPS换算
			- 如何获取VU和TPS
			- 如何评价系统的性能
			- 性能测试策略
			- 总结

		- 性能测试技术指南

			- 适用范围
			- 系统环境
			- 测试指标
			- 业务模型
			- 数据量
			- 测试模型
			- 测试类型
			- 串联链路
			- 场景
			- 监控
			- 瓶颈分析
			- 调优
			- 性能测试分布式云化压测工具

		- 测试指标

			- 编写目的和适用对象
			- 系统性能指标
			- 资源指标
			- 中间件指标
			- 数据库指标
			- 前端指标
			- 稳定性指标
			- 批量处理指标
			- 可扩展性指标
			- 可靠性指标

		- 测试分析及调优

			- 适用对象和范围
			- 性能分析
			- 调优

		- 线上业务压测的核心要素

			- 做到5个一样
			- 业务压测的核心要素
			- 关于压测环境和压测基础数据
			- 关于业务的挡板

	- 不同性能压测工具对比

		- 阿里云PTS
		- Apache JMeter
		- ApacheBench
		- wrk
		- 总结

	- PTS使用指引

### 2022年精选文章

- 代码重构：面向单元测试
- 从业务开发中学习和理解架构设计
- 深度解读 RocketMQ 存储机制
- 提升Java字符串编码解码性能的技巧
- 解决微服务架构下流量有损问题的实践和探索

	- 无损上下线背景

		- 常见的流量有损现象出现的原因

			- 服务⽆法及时下线
			- 初始化慢
			- 注册太早
			- 发布态与运⾏态未对⻬

	- 无损下线

		- 主动通知
		- 自适应等待

	- 无损上线

		- 延迟注册
		- 小流量服务预热
		- 微服务就绪检查

- 淘系用户平台技术团队单元测试建设
- 异步任务处理系统，如何解决业务长耗时、高并发难题？

	- 一  任务处理系统架构

		- 1  任务 API/Dashboard
		- 2  任务分发
		- 3  任务执行

	- 二  大规模多租户异步任务处理系统实践

		- 1  动态队列资源伸缩和流量路由
		- 2  负载随机分片
		- 3  自适应下游处理能力的任务分发
		- 4  向上游的任务生产方发送背压（back pressure）

	- 三  异步任务处理系统的能力分层
	- 四  结论

- Redis消息队列发展历程
- 一文搞懂redis
- 系统性能分析从入门到进阶
- 领域驱动编程，代码怎么写？
- Java应用结构规范
- MySQL 深潜 - MDL 锁的实现与获取机制
- 并发-分布式锁质量保障总结

	- 一  背景
	- 二  分布式锁介绍

		- 1  什么是分布式锁
		- 2  实现分布式锁的主流方式

	- 三  质量保障

		- 1  事前质量保障
		- 2  事中保障
		- 3  事后保障

- 重新认识访问者模式：从实践到本质

	- 一  Calcite 中的访问者模式
	- 二  动手实现访问者模式
	- 三  访问者模式与观察者模式
	- 四  访问者模式与责任链模式
	- 五  访问者模式与回调模式
	- 六  实际应用
	- 七  使用 Java18 实现访问者模式
	- 八  重新认识访问者模式

- 谈一谈单元测试
- Redis 7.0 Multi Part AOF的设计和实现
- Dubbo-go 优雅上下线设计与实践
- Java依赖冲突高效解决之道

	- 一  概述
	- 二  依赖冲突产生的本质原因
	- 三  依赖冲突问题高效定位技巧
	- 四  通过maven调整依赖jar解决依赖冲突
	- 五  通过pandora自定义插件解决依赖冲突
	- 六  通过依赖架构治理解决依赖冲突

- 基于链路思想的SpringBoot单元测试快速写法

### 2021年精选文章

- 软件分析与设计：分析什么？如何设计？
- 阿里巴巴超大规模Kubernetes基础设施运维体系揭秘
- 如何基于LSM-tree架构实现一写多读
- 软件开发架构模式浅谈：一些思考和实践记录
- 开源微服务编排框架：Netflix Conductor
- 并发场景下的幂等问题——分布式锁详解
- 双11实时物流订单最佳实践
- 一文理解 K8s 容器网络虚拟化
- 打通JAVA与内核系列之一ReentrantLock锁的实现原理
- 代理网关设计与实现（基于NETTY）
- 重拾面向对象软件设计
- Kubernetes 入门教程
- Spring Cloud Gateway一次请求调用源码解析
- 庖丁解InnoDB之UNDO LOG
- 并发编程实践之公平有界阻塞队列实现
- 庖丁解InnoDB之REDO LOG
- 函数式编程的Java编码实践：利用惰性写出高性能且抽象的代码
- Java单元测试技巧之JSON序列化
- Effective Java 在工作中的应用总结
- 庖丁解牛-图解MySQL 8.0优化器查询转换篇
- 菜鸟积分系统稳定性建设 - 分库分表&百亿级数据迁移
- 庖丁解牛-图解MySQL 8.0优化器查询解析篇
- 表格存储 SQL 查询多元索引
- 如何避免出现SQL注入漏洞
- 基于 MySQL + Tablestore 分层存储架构的大规模订单系统实践-架构篇
- 当设计模式遇上 Hooks
- 一文详解Redis中BigKey、HotKey的发现与处理
- MySQL 深潜 - 一文详解 MySQL Data Dictionary
- Go 调用 Java 方案和性能优化分享
- 如何设计可靠的灰度方案
- 提升代码质量的方法：领域模型、设计原则、设计模式
- 探究 Java 应用的启动速度优化
- Spring Boot参数校验以及分组校验的使用
- 一文读懂阿里云直播技术是如何实现的
- Java对象转换方案分析与mapstruct实践
- 设计模式在业务系统中的应用
- MySQL 8.0 Server层最新架构详解
- 自己动手从0开始实现一个分布式RPC框架
- 一文了解EPaxos核心协议流程
- DevOps发布策略简介
- 重温设计模式之 Factory
- 谈谈JVM内部锁升级过程
- 从操作系统层面分析Java IO演进之路
- 如何用Netty写一个高性能的分布式服务框架？
- 供应链商品域DDD实践
- 深入理解领域驱动设计中的聚合
- 性能优化：关于缓存的一些思考
- Java编程技巧之样板代码
- 一种低延迟的超时中心实现方式
- 浅谈分布式一致性：Raft 与 SOFAJRaft
- 10问10答：你真的了解线程池吗？
- 从重复到重用
- 参数校验优雅实践
- 殷浩详解DDD：领域层设计规范
- 物联网海量时序数据存储有哪些挑战？
- 收藏！Java编程技巧之单元测试用例编写流程
- 分区取模分库分表策略：多表事务分库内闭环解决方案
- 蚂蚁构建服务演进史
- 殷浩详解DDD：如何避免写流水账代码？
- 如何使用Arthas提高日常开发效率？
- 几种Java常用序列化框架的选型与对比
- 好代码实践：基于Redis的轻量级分布式均衡消费队列
- 小白也能懂的Nacos服务模型
- 那些你不知道的TCP冷门知识！
- 一文详解SQL关联子查询
- ​Java Map中那些巧妙的设计
- 浅谈分库分表那些事儿
- 我在架构设计和代码开发中的一些常用原则
- 应用容灾中，MySQL数据表是否需要跨云同步？
- 这可能是大型复杂项目下数据流的最佳实践
- Java单元测试技巧之PowerMock
- 稳定性保障6步走：高可用系统大促作战指南！
- 收藏！这些IDE使用技巧，你都知道吗
- 256变4096：分库分表扩容如何实现平滑数据迁移？
- Java异步非阻塞编程的几种方式
- 高可用的本质
- 认识长轮询：配置中心是如何实现推送的？
- 多中心容灾实践：如何实现真正的异地多活？
- RocketMQ如何保证消息的可靠性？
- 3+1保障：高可用系统稳定性是如何炼成的？
- 如何优化你的if-else？来试试“责任树模式”
- 如何编写有效的接口测试？
- 一个线上SQL死锁异常分析：深入了解事务和锁
- 跨地域场景下，如何解决分布式系统的一致性？
- 开放下载！1500页，40万字，淘系技术2020总结黑皮书来了
- ​领域模型vs数据模型，应该怎么用？
- 阿里如何做好双11技术保障？大队长霜波分享4点经验
- 复杂系统如何保障代码质量？让测试先行

### 2020年精选文章

- 如何实现Java类隔离加载？
- Spring启动慢？提速利器SpringFu来了
- 史上最轻量​！阿里新型单元测试Mock工具开源了
- 如何做压测？
- 前沿实践：垃圾回收器是如何演进的？
- 线上故障如何快速排查？来看这套技巧大全

	- 一  服务器层面

		- 1.1  磁盘
		- 1.2  CPU过高

	- 二  应用层面

		- 2.1  Tomcat假死案例分析
		- 2.2  应用CPU过高

	- 三  Mysql

		- 3.1  死锁
		- 3.2  慢SQL
		- 3.3  连接数过多
		- 3.4  相关知识
		- 3.5  一些建议

	- 四  Redis 

		- 4.1  问题处理思路
		- 4.2  内存告警
		- 4.3  Redis的慢命令
		- 4.4  连接过多
		- 4.5  线上Redis节点挂掉一个之后的处理流程

	- 五  网络

		- 5.1  排查流程
		- 5.2  相关知识

	- 六  业务异常日志

		- 6.1  问题出现
		- 6.2  日志分析

- 8条经验轻松上手IDEA插件开发

- 底层原理：垃圾回收算法是如何设计的？
- 单元测试难？来试试这些套路
- 如何写好单元测试？
- CPU飙高，系统性能问题如何排查？
- 面对复杂业务，if-else coder 如何升级？
- Java如何支持函数式编程？
- Java编程技巧：如何实现参数的输入输出？
- DDD as Code：如何用代码诠释领域驱动设计？
- 如何基于K8s构建下一代DevOps平台？
- 快速入门数据结构和算法

- Java 开发必备！ I/O与Netty原理精讲
- 正确入门Service Mesh：起源、发展和现状
- 领域驱动设计详解：是什么、为什么、怎么做？
- Java 如何实现动态脚本？
- 如何选择分布式事务解决方案？
- Serverless Kubernetes：理想，现实与未来
- 一文讲透 Git 底层数据结构和原理
- 重启大法好！线上常见问题排查手册
- 架构方法论：如何自底向上推导应用逻辑？
- Java 的这些坑，你踩到了吗？
- 性能提升2.58倍！阿里最快KV存储引擎揭秘
- 阿里高级技术专家：整洁的应用架构“长”什么样？
- 重磅发布 | 380 页高德核心技术公开，速度收藏！

### 2019年精选文章

- Java工程师该如何编写高效代码？

- 拼不过 GO？阿里如何重塑云上的 Java
- ​每秒7亿次请求，阿里新一代数据库如何支撑？
- 90%的人会遇到性能问题，如何用1行代码快速定位？

- 9大技术领域，1500+道面试题出炉！
- 万字长文丨1分36秒，100亿，支付宝技术双11答卷：没有不可能
- 初创公司5大Java服务困局，阿里工程师如何打破？

- 从0到千万DAU，这5年闲鱼架构如何演进？
- Go语言出现后，Java还是最佳选择吗？
- 消灭 Java 代码的“坏味道”
- 从 SOA 到微服务，企业分布式应用架构在云原生时代如何重塑？
- 70+份云栖大会顶级大咖演讲PPT+视频全分享！
- 结构化数据存储，如何设计才能满足需求？
- 如何造一个“钉钉”？谈谈消息系统架构的实现

	- 梗概
	- 功能模块

		- 消息存储

			- 功能：会话窗口消息展示
			- 核心代码

		- 存储库

			- 功能：多维组合、全文检索
			-  核心代码

		- 同步库

			-  功能：新消息即时统计
			- 核心代码
			- 功能：异步写扩散

		- 元数据管理

			- 用户元数据
			-  功能：用户检索
			- 会话元数据
			- 功能：群检索

		- 关系维护

			- 单聊关系

				-  功能：人与单聊会话的关系
				-  功能：人与人的关系
				- 核心代码

		- 群聊关系

			- 功能：群聊会话与人的关系
			- 核心代码
			- 功能：人与群聊会话的关系

	- 即时感知

		- 会话池方案

	- 其他

		- 多端同步
		- 添加好友、入群申请

- 亿级规模的 Feed 流系统，如何轻松设计？

	- 简介
	- Feed流系统特点
	- Feed流系统设计

		- 1. 产品定义
		- 2. 存储
		- 3. 同步
		- 4. 元数据

			- 4.1 用户详情和列表
			- 4.2 关注或好友关系
			-  4.3 推送session池

		- 5. 评论
		- 6. 赞
		- 7. 搜索
		- 8. 排序
		- 9. 删除Feed内容
		- 10. 更新Feed内容
		- 11. 总结

	- 架构实践

- 咱们从头到尾说一次 Java 的垃圾回收
- 阿里毕玄：系统架构师如何做好系统设计？
- 阿里高级技术专家方法论：如何写复杂业务代码？

	- 一个复杂业务的处理过程

		- 业务背景
		- 过程分解
		- 过程分解后的两个问题
		- 过程分解+对象模型

	- 写复杂业务的方法论
	- 业务技术要怎么做

- Alibaba Cloud Linux 2 开源后又有什么新动作？
- 架构整洁之道, 看这一篇就够了！
- 揭秘！现代IM系统的消息架构如何设计？
- 在阿里，我们如何管理测试环境？
- K8S 从懵圈到熟练：读懂此文，集群节点不下线！
- 在阿里，我如何做好一个项目的启动？
- 盘它！40篇+阿里技术经典案例，看完必收藏
- 来了！阿里开源分布式事务解决方案 Fescar

## 美团技术团队

### 1. CompletableFuture原理与实践-外卖商家端API的异步化

- 0 背景
- 1 为何需要并行加载
- 2 并行加载的实现方式

	- 2.1 同步模型
	- 2.2 NIO异步模型
	- 2.3 为什么会选择CompletableFuture？

- 3 CompletableFuture使用与原理

	- 3.1 CompletableFuture的背景和定义

		- 3.1.1 CompletableFuture解决的问题
		- 3.1.2 CompletableFuture的定义

	- 3.2 CompletableFuture的使用

		- 3.2.1 零依赖：CompletableFuture的创建
		- 3.2.2 一元依赖：依赖一个CF
		- 3.2.3 二元依赖：依赖两个CF
		- 3.2.4 多元依赖：依赖多个CF

	- 3.3 CompletableFuture原理

		- 3.3.1 CompletableFuture的设计思想
		- 3.3.2 整体流程

- 4 实践总结

	- 4.1 线程阻塞问题

		- 4.1.1 代码执行在哪个线程上？

	- 4.2 线程池须知

		- 4.2.1 异步回调要传线程池
		- 4.2.2 线程池循环引用会导致死锁
		- 4.2.3 异步RPC调用注意不要阻塞IO线程池

	- 4.3 其他

		- 4.3.1 异常处理
		- 4.3.2 沉淀的工具方法介绍

- 5 异步化收益
- 6 参考文献

### 2. Java系列 | 远程热部署在美团的落地实践

- 1 前言

	- 1.1 什么是热部署
	- 1.2 为什么我们需要热部署

		- 1.2.1 开发自测场景
		- 1.2.2 联调场景

	- 1.3 热部署难在哪
	- 1.4 Sonic可以做什么
	- 1.5 Sonic远程热部署落地推广的实践经验

- 2 整体设计方案

	- 2.1 Sonic结构

	  Sonic插件由4大部分组成，包括脚本端、插件端、Agent端，以及Sonic服务端。脚本端负责自动化构建Sonic启动参数、服务启动等集成工作；IDEA插件端集成环境为开发者提供更便捷的热部署服务；Agent端随项目启动负责热部署的功能实现；服务端则负责收集热部署信息、失败上报等统计工作。
	  

	- 2.2 走进Agent

		- 2.2.1 Instrumentation类常用API
		- 2.2.2 Instrument简介
		- 2.2.3 启动时和运行时加载Instrument Agent过程

	- 2.3 那些年JVM和HotSwap之间的“相爱相杀”
	- 2.4 Sonic如何解决Instrumentation的局限性

- 3 Sonic热部署技术解析

	- 3.1 Sonic整体架构模型
	- 3.2 Sonic功能流转
	- 3.3 文件监听
	- 3.4 JVM Class Reload
	- 3.5 Spring Bean重载
	- 3.6 Spring XML重载
	- 3.7 MyBatis 热部署

- 4 总结

	- 4.1 热部署功能一览
	- 4.2 IDE插件集成
	- 4.3 推广使用情况

- 5. JRebel插件热部署

### 3. （前端）知识图谱可视化技术在美团的实践与探索

知识图谱可视化可以更直观地查看和分析知识图谱的数据。本文主要介绍了美团平台在布局策略、视觉降噪、交互功能、可视化叙事、3D图谱可视化等方面的一些实践和探索，同时沉淀出了uni-graph图可视化解决方案，并支持了美团的很多业务场景，包括美团大脑、图数据库、智能IT运维、组件依赖分析、行业领域图谱等。希望能对从事知识图谱可视化方向的同学有所帮助或启发。


- 1 知识图谱可视化基本概念

	- 1.1 知识图谱技术的简介

	  
	  知识图谱（Knowledge Graph）是人工智能的重要分支，它是一种揭示实体之间关系的语义网络，可以对现实世界的事物及其相互关系进行形式化地描述。举个例子，“孙悟空的师傅是唐僧”就是一条知识。在这条知识里，有“孙悟空”和“唐僧”两个实体，“师傅”是描述这两个实体之间的关系，上述内容在知识图谱中就组成了一个SPO三元组（Subject-Predicate-Object）。
	  
	  
	  所以，对于现实世界中实体之间的关联关系，用知识图谱进行描述的话，就显得非常合适。正是由于知识图谱的这种优势，这项技术得到迅速普及，目前在搜索、推荐、广告、问答等多个领域都有相应的解决方案。
	  
	  

	- 1.2 知识图谱可视化的简介

- 2 场景分析与架构设计

	- 2.1 场景需求分析

		- 图查询应用

		- 图分析应用
		- 技术品牌建设

	- 2.2 技术选型与架构设计

		- D3.js

- 3 技术挑战与方案设计

	- 3.1 布局策略

		- 提取数据特征优化布局

			- 力导向图

		- 层级数据布局方案
		- 布局参数配置化
		- 图数据库可视化-布局样式参数调整
		- 服务链路可视化-平铺层布局参数调整

	- 3.2 视觉降噪

		- 文字处理

			- 四叉树碰撞检测

		- 边处理

			- 多边散列排布
			- 多类型可调节边

				- 贝塞尔曲线控制点

	- 3.3 交互功能

		- 路径锁定
		- 聚焦展现

	- 3.4 美团大脑可视化

		- 多屏适配方案
		- 现场效果
		- 动画脚本自动化
		- 美团大脑功能交互

	- 3.5 可视化叙事的探索

		- 扫光效果
		- 动效节奏调试

	- 3.6 3D可视化场景的探索

		- 节点样式优化
		- 3D动效

			- vasturiano

- 4 落地场景
- 5 未来展望

	- 交互场景
	- 效果呈现

		- WebGL

	- 工具能力

### 4. 设计模式二三事

- 引言
- 1. 奖励的发放策略

	- 1.1 策略模式和适配器模式

	- 1.2 单例模式

- 2. 任务模型的设计

	- 2.1 状态模式

	- 2.2 观察者模式

- 3. 活动的迭代重构

	- 3.1 建造者模式

	- 3.2 装饰器模式

### 5. 可视化全链路日志追踪

- 1. 背景

	- 1.1 业务系统日益复杂
	- 1.2 业务追踪面临挑战

		- 1.2.1 传统的ELK方案

			- 什么是ELK？

		- 1.2.2 分布式会话跟踪方案

			- 参考资料

				- Dapper

				- zipkin

				- skywalking介绍

			- (1) 无法同时追踪多条调用链路
			- (2) 无法准确描述业务逻辑的全景
			- (3) 无法聚焦于当前业务系统的逻辑执行

		- 1.2.3 总结

- 2. 可视化全链路日志追踪

	- 2.1 设计思路

		- 问题1：如何高效组织业务日志？
		- 问题2：如何动态串联业务日志？

	- 2.2 通用方案

		- 2.2.1 链路定义
		- 2.2.2 链路染色
		- 2.2.3 链路上报
		- 2.2.4 链路存储

- 3. 大众点评内容平台实践

	- 3.1 业务特点与挑战
	- 3.2 实践与成果

- 4. 总结与展望

### 如何优雅地记录操作日志？

### Spock单元测试框架介绍以及在美团优选的实践

### 美团终端消息投递服务Pike的演进之路

### 百亿规模API网关服务Shepherd的设计与实现

- 一、背景介绍

	- 1.1 API网关是什么？
	- 1.2 为什么要做Shepherd API网关？
	- 1.3 使用Shepherd带来的收益是什么？

		- 提升研发效率
		- 降低沟通成本
		- 提升资源利用率

- 二、技术设计与实现

	- 2.1 整体架构

		- 2.1.1 控制面
		- 2.1.2 配置中心
		- 2.1.3 数据面

			- 前缀树
			- API路由
			- 功能组件
			- 协议转换&服务调用

	- 2.2 高可用设计

		- 2.2.1 排除性能隐患

			- 发现QPS在超过2000时，会出现很多超时错误，而网关的服务端负载与性能却非常富余
			- API请求预热的优化
			- 通过压测时的CPU热点排查，将性能瓶颈找出，减少主链路上的本地日志打印，对请求日志进行异步化、远程化改造
			- 将Jetty容器全面替换为Netty网络框架

		- 2.2.2 服务隔离

			- 集群隔离
			- 请求隔离

		- 2.2.3 稳定性保障
		- 2.2.4 请求安全
		- 2.2.5 可灰度

			- 灰度场景
			- 灰度策略

		- 2.2.6 监控告警

			- 立体化监控
			- 多维度告警

		- 2.2.7 故障自愈
		- 2.2.8 可迁移

			- 解决方案
			- 灰度过程

	- 2.3 易用性设计

		- 2.3.1 自动生成DSL
		- 2.3.2 API操作提效

			- 快速创建API
			- 批量操作
			- API导入导出

	- 2.4 可扩展性设计

		- 2.4.1 自定义组件
		- 2.4.2 服务编排

			- 美团服务体验平台对接业务数据的最佳实践-海盗中间件

- 三、未来规划

	- 3.1 云原生架构演进

		- 美团Serverless平台Nest的探索与实践

	- 3.2 静态网站托管
	- 3.3 组件市场

### GraphQL及元数据驱动架构在后端BFF中的实践

### OCTO 2.0：美团基于Service Mesh的服务治理系统详解

### 全链路压测自动化实践

- 背景与意义

	- 提供链路梳理工具，能够自动构建压测入口链路完整的依赖信息，辅助链路梳理；
	- 支持链路标注和配置功能，对于无需压测触达的依赖接口，可以通过配置化手段，完成相关接口的Mock配置，不用在业务代码中嵌入压测判断逻辑；
	- 提供抽象的数据构造接口，通过平台，用户可以配置任意的数据构造逻辑和流程；
	- 在压测前/压测中，自动对压测服务和流量做多项校验，保障压测安全性；
	- 在平日，基于压测计划提供周期性小流量的压测校验，使得业务迭代变更带来的压测安全风险被尽早发现；
	- 提供压测计划管理功能，通过系统自动调度和控制施压过程，解放人力；同时强制前置预压测，也提高了安全性；
	- 一键压测，自动生成报告，收集链路入口和告警信息，提供问题记录和跟进功能。

- 系统设计

	- 系统总体设计
	- 链路治理模块设计
	- 数据构造模块设计
	- 压测验证模块设计

		- Mafka
		- Cellar/Squirrel

	- 压测计划管理模块设计

- 案例分享

	- 团队/服务注册
	- 链路治理
	- 应用改造与压测配置
	- Quake准备
	- 数据构造
	- 压测实施

- 总结与展望

### 全链路压测平台（Quake）在美团中的实践

- 1. 背景

  在美团的价值观中，“以客户为中心”被放在一个非常重要的位置，所以我们对服务出现故障越来越不能容忍。特别是目前公司业务正在高速增长阶段，每一次故障对公司来说都是一笔非常不小的损失。而整个IT基础设施非常复杂，包括网络、服务器、操作系统以及应用层面都可能出现问题。在这种背景下，我们必须对服务进行一次全方位的“体检”，从而来保障美团多个业务服务的稳定性，提供优质的用户服务体验。真正通过以下技术手段，来帮助大家吃的更好，生活更好：
  
  验证峰值流量下服务的稳定性和伸缩性。
  验证新上线功能的稳定性。
  进行降级、报警等故障演练。
  对线上服务进行更准确的容量评估。
  ……
  全链路压测是基于线上真实环境和实际业务场景，通过模拟海量的用户请求，来对整个系统进行压力测试。早期，我们在没有全链路压测的情况下，主要的压测方式有：
  
  对线上的单机或集群发起服务调用。
  将线上流量进行录制，然后在单台机器上进行回放。
  通过修改权重的方式进行引流压测。
  但以上方式很难全面的对整个服务集群进行压测，如果以局部结果推算整个集群的健康状况，往往会“以偏概全”，无法评估整个系统的真实性能水平，主要的原因包括：
  
  只关注涉及的核心服务，无法覆盖到所有的环节。
  系统之间都是通过一些基础服务进行串联，如 Nginx、Redis 缓存、数据库、磁盘、网络等等，而基础服务问题在单服务压测中往往不能被暴露出来。
  综合多种因素考虑，全链路压测是我们准确评估整个系统性能水平的必经之路。目前，公司内所有核心业务线都已接入全链路压测，月平均压测次数达上万次，帮助业务平稳地度过了大大小小若干场高峰流量的冲击。
  
  

- 2. 解决方案

	- 提供模拟线上真实流量的能力

	  压测和 DDoS 攻击不同的是，压测有应用场景，而 DDoS 可能只需要一个请求。为了更真实的还原用户行为，我们需要获取线上的真实流量进行压测。
	  

		- DDoS攻击介绍

	- 具备快速创建压测环境的能力

	  这里的环境指的是线上环境，因为如果压测的是线下环境，即使不考虑“机器配置是否相同”这个因素，像集群规模、数据库体量、网络条件等这些因素，在线下环境下都无法进行模拟，这样得出压测结果，其参考价值并不大。
	  

	- 支持多种压测类型

	  压测类型除了支持标准的 HTTP 协议，还需要对美团内部的 RPC 和移动端协议进行支持。
	  

	- 提供压测过程的实时监控与过载保护

	  全链路压测是一个需要实时关注服务状态的过程，尤其在探测极限的时候，需要具备精准调控 QPS 的能力，秒级监控的能力，预设熔断降级的能力，以及快速定位问题的能力。
	  

- 3. Quake 整体架构设计

	- Quake-Web

	  压测管理端，负责压测数据构造、压测环境准备、场景管理、压测过程的动态调整以及压测报表展示等。
	  

	- Quake-Brain

	  调度中心，负责施压资源的调度、任务分发与机器资源管理。
	  

	- Quake-Agent

	  ：压测引擎，负责模拟各种压测流量。
	  

	- Quake-Monitor

	  监控模块，统计压测结果，监控服务各项指标。
	  

- 4. 管理端核心功能

	- 数据构造

		- HTTP 服务的访问日志收集

	- RPC 线上流量实时录制
	- 压测隔离

		- 测试标识透传

			- 跨线程间的透传

				- ThreadLocal 

			- 跨服务间的透传

				- Mtrace

	- 链路诊断

		- Mtthrift(美团RPC框架)
		- Zebra(美团持久层框架)

	- 压测服务隔离
	- 压测数据隔离

		- 影子表如何设计？

- 5. 调度中心核心设计

	- 资源计算

		- 压测期望到达的 QPS。
		- 压测请求的平均响应时间和请求/响应体大小。
		- 压测的词表大小、分片数。
		- 压测类型。
		- 所需压测的机房。

	- 事件注入机制

		- 事件类型

			- 调整 QPS 的事件
			- 触发熔断的事件
			- 开启事故注入
			- 开启代码级性能分析

		- 触发事件

			- 用户手动触发
			- 由于系统保护机制触

	- 机器管理

		- 动态扩容
		- 灰度升级
		- 异常摘除

- 6. 压测引擎优化

	- 性能问题
	- IO 模型优化

		- Reactor 多线程模型

		- 优化一：采用 Reactor 多线程模型
		- 优化二：业务逻辑与 IO 读写事件分离

	- 内存优化

		- 合理分配内存对象
		- JVM 参数调优

- 7. 监控模块

	- 客户端监控
	- 服务端监控
	- 熔断保护机制

- 8. 项目总结

	- 小步快跑
	- 快速响应
	- 项目推广
	- 开放生态
	- 跨团队合作

### 领域驱动设计在互联网业务开发中的实践

- 过度耦合
- 贫血症和失忆症
- 软件系统复杂性应对
- 与微服务架构相得益彰
- 战略建模

	- 领域
	- 限界上下文
	- 划分限界上下文
	- 上下文映射图
	- 战术建模——细化上下文

- DDD工程实现

	- 模块
	- 领域对象
	- 资源库
	- 防腐层
	- 领域服务
	- 数据流转

- 上下文集成

	- 分离领域

### 深度剖析开源分布式监控CAT

- 背景介绍
- 整体设计
- 客户端设计

	- 设计架构
	- API设计

- 序列化和通信
- 客户端埋点
- 遇到的问题
- 服务端设计

	- 架构设计
	- 实时分析
	- 存储设计

- 服务端设计总结
- 总结

### MGW——美团点评高性能四层负载均衡

- 硬件负载均衡成本问题
- LVS的性能问题
- 中断问题以及协议栈路径性能过长问题
- 锁
- 上下文切换
- 集群的高可靠
- 故障切换
- 故障恢复与扩容
- 单机高可靠
- RS可靠性

	- 节点平滑下线
	- 一致性源IP Hash调度器

## 字节跳动技术团队

### 1. 实战！如何从零搭建10万级 QPS 大流量、高并发优惠券系统

- 1. 需求背景
- 2. 需求拆解及技术选型

	- 需求拆解

	  ￼
	  

	- 系统选型及中间件

		- 存储

			- MySQL

		- 缓存

			- Redis

		- 消息队列

			- RocketMQ

		- 系统框架

			- kitex

- 3. 系统开发与实践

	- 系统设计实现
	- 系统整体架构

	  ￼
	  

	- 数据结构 ER 图

	  ￼
	  

	- 核心逻辑实现

		- 发券

			- 1. 如何解决幂等问题？

		- 券过期

- 4. 大流量、高并发场景下的问题及解决方案

	- 存储瓶颈及解决方案

		- 瓶颈

		  
		  在系统架构中，我们使用了 MySQL、Redis 作为存储组件。我们知道，单个服务器的 I/O 能力终是有限的，在实际测试过程中，能够得到如下的数据：
		  
		  单个 MySQL 的每秒写入在 4000 QPS 左右，超过这个数字，MySQL 的 I/O 时延会剧量增长。
		  MySQL 单表记录到达了千万级别，查询效率会大大降低，如果过亿的话，数据查询会成为一个问题。
		  Redis 单分片的写入瓶颈在 2w 左右，读瓶颈在 10w 左右
		  

		- 解决方案

		  读写分离。在查询券模板、查询券记录等场景下，我们可以将 MySQL 进行读写分离，让这部分查询流量走 MySQL 的读库，从而减轻 MySQL 写库的查询压力。
		  分治。在软件设计中，有一种分治的思想，对于存储瓶颈的问题，业界常用的方案就是分而治之：流量分散、存储分散，即：分库分表。
		  发券，归根结底是要对用户的领券记录做持久化存储。对于 MySQL 本身 I/O 瓶颈来说，我们可以在不同服务器上部署 MySQL 的不同分片，对 MySQL 做水平扩容，这样一来，写请求就会分布在不同的 MySQL 主机上，这样就能够大幅提升 MySQL 整体的吞吐量。
		  给用户发了券，那么用户肯定需要查询自己获得的券。基于这个逻辑，我们以 user_id 后四位为分片键，对用户领取的记录表做水平拆分，以支持用户维度的领券记录的查询。
		  每种券都有对应的数量，在给用户发券的过程中，我们是将发券数记录在 Redis 中的，大流量的情况下，我们也需要对 Redis 做水平扩容，减轻 Redis 单机的压力。
		  
		  

		- 容量预估

		  
		  基于上述思路，在要满足发券 12w QPS 的需求下，我们预估一下存储资源。
		  
		  
		  a. MySQL 资源
		  
		  
		  在实际测试中，单次发券对 MySQL 有一次非事务性写入，MySQL 的单机的写入瓶颈为 4000，据此可以计算我们需要的 MySQL 主库资源为：
		  
		  120000/4000 = 30
		  
		  b. Redis 资源
		  
		  
		  假设 12w 的发券 QPS，均为同一券模板，单分片的写入瓶颈为 2w，则需要的最少 Redis 分片为：
		  
		  120000/20000 = 6
		  

	- 热点库存问题及解决方案

		- 问题

		  大流量发券场景下，如果我们使用的券模板为一个，那么每次扣减库存时，访问到的 Redis 必然是特定的一个分片，因此，一定会达到这个分片的写入瓶颈，更严重的，可能会导致整个 Redis 集群不可用。
		  

		- 解决方案

		  
		  热点库存的问题，业界有通用的方案：即，扣减的库存 key 不要集中在某一个分片上。如何保证这一个券模板的 key 不集中在某一个分片上呢，我们拆 key（拆库存）即可。如图：
		  
		  
		  

		- 建券
		- 库存扣减

	- 券模板获取失败问题及解决方案

		- 问题
		- 解决方案

- 5. 服务治理

  
  系统开发完成后，还需要通过一系列操作保障系统的可靠运行。
  
  超时设置。优惠券系统是一个 RPC 服务，因此我们需要设置合理的 RPC 超时时间，保证系统不会因为上游系统的故障而被拖垮。例如发券的接口，我们内部执行时间不超过 100ms，因此接口超时我们可以设置为 500ms，如果有异常请求，在 500ms 后，就会被拒绝，从而保障我们服务稳定的运行。
  监控与报警。对于一些核心接口的监控、稳定性、重要数据，以及系统 CPU、内存等的监控，我们会在 Grafana 上建立对应的可视化图表，在春节活动期间，实时观测 Grafana 仪表盘，以保证能够最快观测到系统异常。同时，对于一些异常情况，我们还有完善的报警机制，从而能够第一时间感知到系统的异常。
  限流。优惠券系统是一个底层服务，实际业务场景下会被多个上游服务所调用，因此，合理的对这些上游服务进行限流，也是保证优惠券系统本身稳定性必不可少的一环。
  资源隔离。因为我们服务都是部署在 docker 集群中的，因此为了保证服务的高可用，服务部署的集群资源尽量分布在不同的物理区域上，以避免由集群导致的服务不可用。
  

- 6. 系统压测及实际表现

	- 注意事项
	- 结论
	- 系统的业务思考

- 7. 总结

  
  从零搭建一个大流量、高并发的优惠券系统，首先应该充分理解业务需求，然后对需求进行拆解，根据拆解后的需求，合理选用各种中间件；本文主要是要建设一套优惠券系统，因此会使用各类存储组件和消息队列，来完成优惠券的存储、查询、过期操作；
  
  
  在系统开发实现过程中，对核心的发券、券过期实现流程进行了阐述，并针对大流量、高并发场景下可能遇到的存储瓶颈、热点库存、券模板缓存获取超时的问题提出了对应的解决方案。其中，我们使用了分治的思想，对存储中间件进行水平扩容以解决存储瓶颈；采取库存拆分子库存思路解决热点库存问题；引入本地缓存解决券模板从 Redis 获取超时的问题。最终保证了优惠券系统在大流量高并发的情景下稳定可用；
  
  
  除开服务本身，我们还从服务超时设置、监控报警、限流、资源隔离等方面对服务进行了治理，保障服务的高可用；
  
  
  压测是一个新服务不可避免的一个环节，通过压测我们能够对服务的整体情况有个明确的了解，并且压测期间暴露的问题也会是线上可能遇到的，通过压测，我们能够对新服务的整体情况做到心里有数，对服务上线正式投产就更有信心了。
  

### 2. 2022 春节抖音视频红包系统设计与实现

- 1. 我们做了什么

	- 业务背景
	- 业务玩法

		- B2C 红包
		- C2C 红包

	- 红包领取
	- 卫视春晚演示视频

- 2. 我们碰到的一些问题

	- 通用红包系统的设计
	- 大流量补贴的发放处理
	- 红包领取方案的选型
	- 稳定性容灾
	- 资金安全保证
	- 红包系统的压测

- 3. 我们怎么做的

	- 1. 通用红包系统的设计

		- 划分原则

			- 功能内聚，每个系统只处理一个任务，方便之后系统的开发和迭代，以及问题的排查
			- API 网关层只进行简单的 proxy 处理
			- 异步任务拆解
			- 读写分离，将红包的核心操作和红包的查询分成两个服务

		- 划分模块

			- 红包网关服务
			- 红包核心服务
			- 红包查询服务
			- 红包异步服务
			- 红包基础服务
			- 红包对账服务

		- 整体架构

	- 2. 大流量补贴的发放处理

		- 同步奖励发放
		- 异步奖励发放

			- 但是在异步的方式中，整个补贴的入账预估需要 10min，而用户在 APP 界面感知到发券后可能马上就会开始使用用补贴来发放视频红包，或者会去红包挂件查看自己已经领取的红包补贴，而此时补贴还未在红包系统中入账。

		- 最终方案

			- 1. 在用户使用红包补贴进行视频红包发放时，我们会先对该补贴进行一个入库操作，入库成功后才可以用这个补贴进行红包发放

	- 3. 红包领取方案的选型

		- 悲观锁方案
		- 红包预拆分方案
		- 最终方案

			- 红包 redis 限流

			  为尽可能少的减少 DB 锁冲突，首先会按照红包单号进行限流，每次允许剩余红包个数*1.5 的请求量通过。被限流返回特殊错误码，前端最多轮训 10 次，在请求量过多的情况下通过这种方式来慢慢处理
			  
			  

			- 内存排队

			  除了 redis 限流外，为了减少 DB 锁，我们在领取流程中加个一个红包内存锁，对于单个红包，只有获取到内存锁的请求才能继续去请求 DB，从而将 DB 锁的冲突迁移到内存中提前处理，而内存资源相对于 DB 资源来说是非常廉价的，在请求量过大时，我们可以水平扩容。
			  为了实现内存锁，我们进行了几个改动。首先需要保证同一个红包请求能打到同一个 tce 实例上，这里我们对网关层路由进行了调整，在网关层调用下游服务时，会按照红包单号进行路由策略，保证同一单号的请求打到同一个实例上。另外我们在红包系统的 core 服务中基于 channel 实现了一套内存锁，在领取完成后会释放该红包对应的内存锁。另外为了防止锁的内存占用过大或者未及时释放，我们起了一个定时任务去定期地处理。
			  
			  

			- 转账异步化

			  从接口耗时来看，转账是一个耗时较长的操作，本身涉及和第三方支付机构交互，会有跨机房请求，响应延时较长，将转账异步化可以降低领取红包接口的时延，提高服务性能和用户体验
			  另外从用户感知来看，用户更关注的是领取红包的点击开后是否领取成功，至于余额是否同步到账用户其实感知没那么强烈，另外转账本身也是有一个转账中到转账成功的过程，将转账异步化对于用户的感知基本没有影响
			  
			  

	- 4. 稳定性容灾

		- 接口限流
		- 业务降级

			- 核心依赖降级
			- 非核心依赖降级

		- 多重机制保证状态机的推进

	- 5. 资金安全保证

		- 交易幂等

			- 另外红包系统的补贴发放接口是幂等的，外部同一个单号多次请求发放补贴，我们需要保证只会发一张券

				- 1. 一个单号一张券

			- 同一个外部单号更换了 uid，就可能会导致两个请求分别打到不同的数据库实例上，导致唯一索引失效，造成资损

				- 1. 什么情况下会更换uid?

			- 我们又额外的引入一个以补贴发放外部单号作为分片键的数据库来解决这个风险

				- 1. 同一订单只会请求同一分片数据库

		- B2C 红包核对
		- C2C 红包核对

		  在 C2C 链路中，整个主要从用户发起支付，到用户领取转账以及最后红包过期退款。在支付，转账，退款这三个流程都需要进行相应的核对。同时，还需要保证用户的红包发放金额大于等于红包转账金额+红包退款金额，这里大于等于是因为红包从发放成功到退款成功整个周期会在 24h 以上，另外可能存在转账在途的这种订导致会有多笔退款单，如果要求严格等于的话具体对账时机没法控制。
		  

	- 6. 红包系统的压测

	  
	  前面提到过，红包系统的链路包含有多个接口，发领查等，需要模拟用户的真实行为来进行压测才能得到系统的真实性能。这里我们使用了压测平台的脚本压测方式来进行压测。
	  
	  
	  首先需要对整个压测链路整个改造，和上下游沟通是否可以压测，不能压测的需要进行相应的 mock 处理。另外对于存储服务，数据库，redis 和 mq 都要确保压测标的正确传递，否则可能会影响到线上。
	  
	  
	  改造完压测链路后，需要构造相应的压测脚本，对于 B2C 和 C2C 分为两个脚本。
	  
	  

		- B2C 红包链路压测
		- C2C 红包链路压测

- 4. 后续规划

	- 服务 Set 化

### 3. 抖音支付十万级 TPS 流量发券实践

- 背景
- 抖音支付营销系统简介
- 挑战
- 方案

	- 性能保障
	- 异步发券-提升接口响应速度

		- 1. 如何判断异刷单用户，进行拦截？

	- 双层本地队列-提升处理能力，平滑流量
	- 库存扣减优化-减热点，降压力

		- 1. 有限次重试设置多少？
		- 2. 为什么要退出while循环？
		- 3. 如何合并相同券批次？
		- 4. 为什么要用本地内存保存库存信息？

	- 优雅退出-完善系统鲁棒性

		- 1. 远程队列是指什么？
		- 2. 收不到Sign信号怎么办？

	- 兜底补偿-保证最终一致性

		- 1. 券的中间状态有哪些？
		- 2. 设置多久重新投递数据？
		- 3. 有了定时任务为什么还需要优雅退出？

	- 绿色通道-提升用户体验

		- 1. 如何修改成同步？

- 资金防控

	- 幂等校验

		- 1. 数据库幂等压力过大怎么办？
		- 2. 数据库分片之后唯一索引失效怎么办？

	- 用户维度领取限制
	- 券批次组互斥

		- 1. 券批次组如何划分？

	- 库存防超卖

		- 1. 库存少卖是什么情况？

- 风控平台接入

	- 1. 如何接入？

- 数据监控与核对
- 总结
- 后续规划

### 4. 春节钱包大流量奖励系统入账及展示的设计与实现

- 1. 背景&挑战&目标

	- 1.1 业务背景

	  
	  （1）支持八端：2022 年字节系产品春节活动需要支持八端 APP 产品（包含抖音/抖音火山/抖音极速版/西瓜/头条/头条极速版/番茄小说/番茄畅听）的奖励互通。用户在上述任意一端都可以参与活动，得到的奖励在其他端都可以提现与使用。
	  
	  （2）玩法多变：主要有集卡、朋友页红包雨、红包雨、集卡开奖与烟火大会等。
	  
	  （3）多种奖励：奖励类型包含现金红包、补贴视频红包、商业化广告券、电商券、支付券、消费金融券、保险券、信用卡优惠券、喜茶券、电影票券、dou+券、抖音文创券、头像挂件等。
	  
	  

		- 1. 支持八端
		- 2. 玩法多变
		- 3. 多种奖励

	- 1.2 核心挑战

	  
	  （1）设计&实现八端奖励入账与展示互通的大流量的方案，最高预估有 360w QPS 发奖。
	  
	  （2）多种发奖励的场景，玩法多变；奖励类型多，共 10 余种奖励。对接多个下游系统。
	  
	  （3）从奖励系统稳定性、用户体验、资金安全与运营基础能力全方位保障，确保活动顺利进行 。
	  
	  

		- 1. 360W的QPS
		- 2. 奖励多样

	- 1.3 最终目标

	  
	  （1）奖励入账：设计与实现八端奖励互通的奖励入账系统，对接多个奖励下游系统，抹平不同奖励下游的差异，对上游屏蔽底层奖励入账细节，设计统一的接口协议提供给业务上游。提供统一的错误处理机制，入账幂等能力和奖励预算控制。
	  
	  （2）奖励展示/使用：设计与实现活动钱包页，支持在八端展示用户所获得的奖励，支持用户查看、提现（现金），使用卡券/挂件等能力。
	  
	  （3）基础能力：
	  【基础 sdk】提供查询红包余额、累计收入、用户在春节活动是否获得过奖励等基础 sdk，供业务方查询使用。
	  【预算控制】与上游奖励发放端算法策略打通，实现大流量卡券入账的库存控制能力，防止超发。
	  【提现控制】在除夕当天多轮奖励发放后，提供用户提现的灰度放量能力、提现时尚未入账的处理能力。
	  【运营干预】活动页面灵活的运营配置能力，支持快速发布公告，及时触达用户。为应对黑天鹅事件，支持批量卡券和红包补发能力。
	  
	  （4）稳定性保障：在大流量的入账场景下，保证钱包核心路径稳定性与完善，通过常用稳定性保障手段如资源扩容、限流、熔断、降级、兜底、资源隔离等方式保证用户奖励方向的核心体验。
	  
	  （5）资金安全：在大流量的入账场景下，通过幂等、对账、监控与报警等机制，保证资金安全，保证用户资产应发尽发，不少发。
	  
	  （6）活动隔离：实现内部测试活动、灰度放量活动和正式春节活动三个阶段的奖励入账与展示的数据隔离，不互相影响。
	  
	  

		- （1）奖励入账
		- （2）奖励展示/使用
		- （3）基础能力
		- （4）稳定性保障
		- （5）资金安全
		- （6）活动隔离

- 2. 产品需求介绍

	- 业务流程

	  登录抖音 → 参与活动 → 活动钱包页 → 点击提现按钮 → 进入提现页面 → 进行提现 → 提现结果页，另外从钱包页也可以进入活动钱包页。
	  

	- 奖励发放核心场景

	  集卡：集卡抽卡时发放各类卡券，集卡锦鲤还会发放大额现金红包，集卡开奖时发放瓜分奖金和优惠券；
	  红包雨：发红包、卡券以及视频补贴红包，其中红包和卡券最高分别 180w QPS；
	  烟火大会：发红包、卡券以及头像挂件。
	  
	  

- 3. 钱包资产中台设计与实现

  在 2022 年春节活动中，UG 主要负责活动的玩法实现，包含集卡、红包雨以及烟火大会等具体的活动相关业务逻辑和稳定性保障。而钱包方向定位是大流量场景下实现奖励入账、奖励展示、奖励使用与资金安全保障的相关任务。其中资产中台负责奖励发放与奖励展示部分。
  

	- 3.1 春节资产资产中台总体架构图如下：

	  ￼
	  
	  钱包资产中台核心系统划分如下：
	  
	  资产订单层：收敛八端奖励入账链路，提供统一的接口协议对接上游活动业务方如 UG、激励中台、视频红包等的奖励发放功能，同时对上游屏蔽对接奖励业务下游的逻辑处理，支持预算控制、补偿、订单号幂等。
	  活动钱包 api 层：收敛八端奖励展示链路，同时支持大流量场景
	  

		- 字节跳动自研强一致在线 KV &表格存储实践 - 上篇

		- Abase2：字节跳动新一代高可用 NoSQL 数据库

	- 3.2 资产订单中心设计

		- 核心发放模型
		- 说明
		- 实现效果
		- 订单号设计

- 4. 核心难点问题解决

	- 4.1 难点一：支持八端奖励数据互通

	  前文背景已经介绍过了，参与 2022 年春节活动一共有八个产品端，其中抖音系和头条系 APP 是不同的账号体系，所以不能通过用户 ID 打通奖励互通。具体解决方案是字节账号中台打通了八端的账号体系给每个用户生成唯一的 actID（手机号优先级最高，如果不同端登录的手机号一样，在不同端的 actID 是一致的）。钱包侧基于字节账号中台提供的唯一 actID 基础上，设计实现了支持八端奖励入账、查看与使用的通用方案，即每个用户的奖励数据是绑定在 actID 上的，入账和查询是通过 actID 维度实现的，即可实现八端奖励互通。
	  

		- 字节账号中台打通了八端的账号体系给每个用户生成唯一的 actID（手机号优先级最高，如果不同端登录的手机号一样，在不同端的 actID 是一致的）

	- 4.2 难点二：高并发场景下的奖励入账实现

	  
	  每年的春节活动，发现金红包都是最关键的一环，今年也不例外。有几个原因如下：
	  
	  预估发现金红包最大流量有 180w TPS。
	  现金红包本身价值高，需要保证资金安全。
	  用户对现金的敏感度很高，在保证用户体验与功能完整性同时也要考虑成本问题。
	  
	  终上所述，发现金红包面临比较大的技术挑战。
	  
	  

		- 4.2.1 红包雨 token 方案：

			- 设计目标：
			- 具体设计方案：

			  我们在大流量场景下每次给用户发红包会生成一个加密 token（使用非对称加密，包含发红包的元信息：红包金额，actID，与发放时间等），分别存储在客户端和服务端（容灾互备），每个用户有个 token 列表。每次发红包的时候会在 Redis 里记录该 token 的入账状态，然后用户在活动钱包页看到的现金红包流水、余额等数据，是合并已入账红包列表+token 列表-已入账/入账中 token 列表的结果。同时为保证用户提现体验不感知红包压单流程，在进入提现页或者点击提现时将未入账的 token 列表进行强制入账，保证用户提现时账户的余额为应入账总金额，不 block 用户提现流程。
			  

				- 1. 红包带token入账流程
				- 2. 红包流水merge流程
				- 3. 点击提现红包token强入账流程

			- token 数据结构：
			- token 状态机流转：
			- token 安全性保障：

		- 4.2.2 活动钱包页展示红包流水

	- 4.3 难点三：发奖励链路依赖多的稳定性保障

		- 解决方案：

			- 避免超发

	- 4.4 难点四：大流量发卡券预算控制

		- 需求背景：
		- 具体实现：
		- 具体流程图：
		- 优化方向：

			- 1. 如何拆key?
			- 2. 为什么redis超时会多消耗库存少发？

	- 4.5 难点五：高 QPS 场景下的热 key 的读取和写入稳定性保障

	  
	  需求背景：
	  
	  
	  在除夕晚上 7 点半开始会开始烟火大会活动，展示所有红包雨与烟火大会红包的实时累计发放总额，最大流量预估读取有 180wQPS，写入 30wQPS。
	  
	  
	  这是典型的超大流量，热点 key、更新延迟不敏感，非数据强一致性场景（数字是一直累加），同时要做好容灾降级处理，最后实际活动展示的金额与产品预计发放数值误差小于 1%。
	  
	  

		- 4.5.1 方案一

			- 具体写入流程：

				- 1. 为什么不能保证幂等性？

			- 读取流程：
			- 问题：

		- 4.5.2 方案二

			- 设计思路：
			- 具体设计方案：
			- 读取流程：

				- 1. 为什么说每次启动第一秒会阻塞？

			- 写入流程：

		- 4.5.3 方案对比

	- 4.6 难点六：进行母活动与子活动的平滑切换
	- 4.7 难点七：大流量场景下资金安全保障

- 5. 通用模式抽象

	- 5.1 容灾降级层面

	  大流量场景，为了保证活动最终上线效果，容灾是一定要做好的。参考业界通用实现方案，如降级、限流、熔断、资源隔离，根据预估活动参与人数和效果进行使用存储预估等。
	  

		- 5.1.1 限流层面
		- 5.1.2 降级层面
		- 5.1.3 资源隔离层面
		- 5.1.4 存储预估
		- 5.1.5 压测层面

	- 5.2 微服务思考

- 6. 系统的未来演进方向

### 5. 大流量活动下钱包提现方案的设计与实现

- 一、活动背景与交互流程

	- 交互流程

		- 1. 进入活动钱包页
		- 2. 点击去提现
		- 3. 选择金额
		- 4. 选择银行卡
		- 5. 确认提现

- 二、大流量下的主要问题

	- 1. 入账延迟与提现限制

	  此时面对上百万 QPS 的用户奖励入账，可能存在部分请求入账存在延迟，导致用户在提现的时候看到的金额与活动参与获得奖励金额不一致的情况。
	  

		- 1. 入账百万QPS
		- 2. 看到金额与获得奖励金额不一致

	- 2. 高并发

	  集卡开奖与红包雨后，提现入口打开时将面对几十万的请求流量，经过用户选择到账方式和输入提现金额后也有数万 QPS 的提现下单请求。钱包服务端收到请求后会操作扣除用户的活动账户余额，接着调用财经侧（字节内部的支付中台）请求出款，财经侧维护与各支付机构（支付宝、银网联）的接入交互。但各支付机构分配给各单位的出款请求流量有限额，字节这边获得的容量与提现出款相差了一个数量级。此时需要在保障用户的提现体验不受影响的同时，又能够确保下游渠道侧不会因流量较高导致可用性抖动。
	  

		- 1. 提现入口几十万流量
		- 2. 各支付机构分配给各单位的出款请求流量有限额
		- 3. 如何保证提现体验不受影响同时确保下游渠道侧不会因流量较高导致可用性抖动？

	- 3. 资金安全

	  提现是春节活动的最后一道流程，公司在用户的春节活动收入账户进行扣款并将资金通过预先设置的备付金账户转入至端上绑定的个人账户中，从而使获得的奖励最终落地。如果用户在端上的操作出现打款超额等情况，一旦出款成功则基本不会有追回的可能，因此，资金安全是提现业务开发过程中必须考虑并保证的部分，确保每笔出款有迹可循且符合提现规则。
	  

		- 打款超额

- 三、设计方案

  
  为解决上述问题，我们通过 RocketMQ 进行异步出款来保证用户体验，同时 RocketMQ 的使用还可以对银行卡等出款渠道进行削峰来减少下游的过高流量。在资金安全方面，每笔订单在进行春节活动收入账户扣款和现金出款时做了幂等操作，并增加对账任务对所有流水进行对账校验。
  
  
  

	- 1. 延时放量

		- 1. 红包token列表是什么？
		- 2. 弱依赖请求和强依赖请求是什么？
		- 3. 如何设计延时放量？

	- 2. MQ 异步出款

	  
	  在除夕当天的晚上 19:00 到春节凌晨 01:00 时间段内，春节活动钱包页中会暂时关闭提现功能，进行部分营销导流。而随着凌晨 01:00 提现开关打开，请求会蜂拥而至逐步上涨至数万 QPS，但由于银网联的处理能力有限，导致银行卡渠道出款最高可支持的 QPS 只有几千。此时如果提现模块不进行限速下单的话，可能存在下游系统被压垮引起雪崩的风险，同时用户会给感受到提现功能卡顿并频繁失败。
	  
	  
	  为解决该问题，我们引入了 RocketMQ 来进行异步出款。当用户在钱包页进行提现操作时，服务端会在春节活动收入账户扣款完成后立即返回结果并跳转至提现结果页面展示当前状态，同时将当前请求参数发送至 MQ 中进行异步消费出款。这样给用户的感觉即账户余额已扣除，提现出款进行中，稍后也可以通过账单流水查询提现结果。
	  
	  

		- 1. 哪些情况会消费失败？
		- 2. 重试队列和死信队列是什么？

		- 2.1 定时任务

	- 3. 提现资金安全

	  在提现的过程中，一旦技术方案设计有问题，容易存在资金安全问题：账户未扣款但现金已转入用户的个人账户，账户多次扣款或者现金多次出款等。因此，在春节活动中提现模块的设计中，资金安全问题是重点考虑的部分。在提现请求发生时，服务端需要确保每笔订单一定对应一次账户余额扣减，一次现金出款。而提现完成后，需要有对账任务与账户和财经出款进行对账，分别对提现订单的金额和状态进行校验，保证事件中的验证无误。
	  

		- 3.1 订单幂等

			- 1. 如何实现幂等性校验

		- 3.2 对账校验

			- 准实时对账

				- 1. 与账户侧准实时对账：
				- 2. 与财经侧准实时对账：
				- 如何消费提现数据库的binlog?

			- 天级对账

				- 1. 为什么选择hive?

				- 2. 什么是网络抖动引发的误报？

- 四、前期预案

	- 1. 提前演练
	- 2. 充分压测

		- 1. 集群隔离如何实现？
		- 2. 如何评估春节活动最高QPS所需要的资源容量？

	- 3. 除夕当日执行脚本

	  执行细节。从除夕上午十点开始到初一凌晨两点，每场红包雨前需要做什么准备，红包雨发生时需要查看哪些监控指标，红包雨后是否需要记录数据等，执行剧本需要详细记录每个时间点需要做的事情。
	  配置校验。提现业务在春节活动上有活动配置与限流等。在活动开始前需要再次做一遍检查，确保各项配置和限流均正确无误。
	  容灾方案。除执行细节和配置校验外，我们还在剧本中加入了容灾预案，方便在某项流程出现问题的时候能够及时根据预案进行处理。
	  交叉检查。剧本中的各项操作细节和配置检查均为两个人分工进行，通过交叉检查的方式防止出现一人疏忽大意而错误改动的情况。
	  
	  

- 五、活动总结

### 6. 字节跳动是怎么做全链路压测的？

- 背景
- 压测方案
- 网络架构
- 压测目的与方案

	- 压测目标
	- 环境隔离
	- 压测标记
	- 压测开关

	  为了强化压测流量的管理，服务治理体系引入了压测开关的概念。压测开关作为总控制，所有服务框架必须判断压测开关是否打开，若打开才能允许通过压测流量，若关闭则只能拒绝压测流量。
	  

	- 存储隔离方案

- 平台搭建

	- Rhino 压测平台

- 压测方式

	- Fake 流量
	- 自定义插件发压
	- 流量录制回放
	- 流量调度
	- 压测方式对比

- 监控

	- 实时监控
	- 服务端监控
	- Ms 报警监控

- 分析&优化

	- 分析方法

		- 监控分析
		- Lidar 性能平台
		- 系统层 tracing 分析

- 常见问题

### 7. 字节跳动全链路压测(Rhino)的实践

- 1. 背景
- 2. 解决方案

	- 2.1 业内实践

		- 美团的 Quake[3][4]

		- 阿里的 Amazon、PTS

		- 京东的的 ForceBOT[5]
		- 高德的 TestPG[6]

	- 2.2 架构图

- 3. 核心功能介绍

	- 3.1 数据构造

		- 基础数据构造

		  
		  压测过程中数据构造是最重要，也是最为复杂的环节。压测数据的建模，直接影响了压测结果的准确性。
		  
		  对于服务性能缺陷扫描，性能调优，以及新上线服务，推荐构造 Fake 数据，来压测指定路径。
		  对于线上容量规划，性能能力验证，以及性能 Diff，推荐使用线上真实流量，使压测结果更贴近真实情况。
		  对于涉及到用户账号，用户登录态保持的情况，推荐使用压测专属测试账号，避免影响线上真实用户。
		  

		- 压测账号

	- 3.2 压测隔离

		- 压测标记
		- 压测标记透传
		- 压测开关
		- 压测数据隔离

		  线上压测中，最复杂的问题就是压测链路中涉及到写操作，如何避免污染线上数据，并且能保证压测请求保持和线上相同的请求路径。业界有很多解决方案，常见的有影子表，影子库，以及数据偏移，如图[7]。
		  

			- MySQL、MongoDB：影子表。SDK 判断是否是压测流量，若是则根据配置映射至新表名。配置策略有两种，一是读写影子表，二是读线上表、写影子表。
			- Redis：Redis Key 加上 Stress 前缀。如 Stress_Tag=Valuex，那么读写 Redis 的 Key=Valuex_Key。这样可以解决多个压测任务数据冲突的问题。压测结束后，只需要对 Prefix=Valuex 做清除或过期操作即可。
			- MQ：对于消息队列，Rhino 平台有两种策略。一是直接丢弃，然后针对消息队列的性能，单独进行压测；二是在 Header 中透传压测标记，Consumer 根据压测标记和业务需求，再做特殊处理。默认走丢弃策略，业务方可根据需求进行配置。
			- 其他存储，如 ES，ClickHouse 等，都有压测集群。压测时，会将压测请求打到指定的压测集群中。

		- 服务压测改造

	- 3.3 链路治理

		- 链路梳理
		- 压测周知
		- 压测开关管理
		- 服务 Mock

			- Service Mesh

	- 3.4 发压模式

		- 最小调度单元
		- 智能压力调节
		- 压测链路模拟
		- 同城多机房，异地多机房
		- 边缘计算节点 Agent

	- 3.5 压测熔断

		- 基于告警监控的熔断
		- 基于 Metric 的熔断

	- 3.6 任务模型

		- HTTP 任务
		- RPC 任务

			-  IDL

		- 自定义-Go Plugin

			- 什么是.so文件

	- 3.7 压测引擎

		- 单 Agent 多引擎
		- 压测引擎

			- Gatling

	- 3.8 压测监控

		- 客户端监控
		- 服务端监控
		- 性能 Profile

- 4. 压测实践

	- 4.1 重大项目支撑
	- 4.2 日常压测任务支撑
	- 4.3 线上流量调度
	- 4.4 常态化压测
	- 4.5 DevOps 流水线中的压测

- 5. 总结与展望

	- 5.1 总结
	- 5.2 未来发展

		- 业务深层次定制化
		- 压测与容量规划
		- 压测与 SRE

- 6. 招聘

## 腾讯技术工程

### 1. 肝货！万字长文助你上手DDD
（阅读时间：2小时）

- 1.背景
- 2.DDD概要与实践感悟

	- 2.1 复杂性

		- 规模：指的是系统所支持的功能点，以及功能点与功能点之间的的关系。DDD通过子领域，限界上下文，聚合等模式对问题进行拆分和归类，不断收窄问题域，保证聚合边界内所解决的问题集合足够收敛和可控。
		- 结构：指的是系统架构。系统架构是否分层；若分层，每层划分的职责边界是否清晰；架构的基本管理单元是什么，它决定了架构演进时的复杂度。DDD通过分层架构，独立出领域层，且架构中的每层都有清晰的职责。整体架构的基本管理单元是聚合，它是一个完整的、自治的管理单元，当需要进行服务拆分时，可以直接以聚合作为基本单元进行拆分。
		- 变化：指的是系统响应需求变化的能力。快速响应变化的有效手段是分离不易变逻辑和易变逻辑，"以不变应万变"。而通过分层架构独立的领域层正是不易变的逻辑。领域层是对领域知识的封装，其提供的领域服务具有经验性和前瞻性，是对领域内稳定的领域规则的表达。而领域层以外的应用层和基础设施层则是易变逻辑的封装。保证核心的独立和稳定，通过在调整应用层和基础设施层来实现快速响应需求变化。

	- 2.2 领域驱动

		- 思维模式转变
		- 协同方式转变
		- 精炼循环

	- 2.3 怎么才算DDD？

		- 构建出产品、领域专家和研发同学认知一致且便于交流的模型，并且模型与实现紧密绑定；
		- 模型逐步演进，反复消化和精炼；
		- 模型蕴含领域知识，足够稳定。

- 3.问题空间&解空间

	- 3.1 问题空间&解空间
	- 3.2 示例-学生管理系统的问题空间

- 4.领域驱动设计统一过程（DDDRUP）
- 5.全局分析阶段

	- 5.1 形成统一语言
	- 5.2 价值需求分析
	- 5.3 业务需求分析

		- 5.3.1 业务流程、业务场景、业务服务和业务规则

			- 业务流程：表示的是一个完整的、端对端的服务过程。
			- 业务场景：按阶段性的业务目标划分业务流程，就可以获得业务场景。在示例-SMS中，老师修改成绩就分为了老师“提交申请单”，以及教务员“同意申请单”两个场景。
			- 业务服务：角色主动向目标系统发起服务请求完成一次完整的功能交互，以实现业务目标。角色可以用户、策略（定时任务）或者其他系统，完整则强调的是业务服务的执行序列的所有步骤都应该是连续且不可中断的。业务服务是业务需求分析最核心，也是最基础的单元，而业务流程和业务场景是为了更好地分析出业务服务。在示例-SMS中的“同意申请单”场景中包含了两个业务服务：教务员“同意申请单”和系统“邮件通知”教务员。
			- 业务规则：指对业务服务约束的描述，用于控制业务服务的对外行为。业务规则是业务服务正确性的基础。常见的业务规则有：a) 意如“若… , 就….” 的需求描述，比如示例-SMS中可提炼出“若成绩录入时间间隔超过一周，不予修改”；b) 具有事务性的操作。

		- 5.3.2 子领域

		  通过业务流程、业务场景和业务服务的梳理，基本可以分析出业务需求所需要的业务服务。然而，业务服务粒度太细，而问题空间又太大，我们需要找一个更粗粒度的业务单元，来帮助我们对业务服务进行聚类，一方面可以降低管理过多细粒度业务服务导致的额外复杂度，另一方面可以帮助领域专家和开发团队分析问题和设计方案时不至于陷入到业务细节中。而这个更粗粒度的业务单元就是子领域。
		  

			- 子领域的作用：

				- 划分问题空间，作为业务服务分类的边界；
				- 用于分辨问题空间的核心问题和次要问题。

			- 子领域的分类：

				- 核心子领域：能够体现系统愿景，具有产品差异化和核心竞争力的业务服务；
				- 通用子领域：包含的内容缺乏领域个性，具有较强的通用性，例如权限管理和邮件管理；
				- 支撑子领域：包含的内容多为“定制开发”，其为核心子领域的功能提供了支撑。

			- 子领域的功能分类策略：问题空间应该分为哪些子领域，需要团队对目标系统整体进行探索，并根据功能分类策略进行分解。

				- 业务职能：当目标系统运用于企业的生产和管理时，与目标系统业务有关的职能部门往往会影响目标系统的子领域划分，并形成一种简单的映射关系。这是康威定律的一种运用。
				- 业务产品：当目标系统为客户提供诸多具有业务价值的产品时，可以按照产品的内容与方向进行子领域划分。
				- 业务环节：对贯穿目标系统的核心业务流程进行阶段划分，然后按照划分出来的每个环节确定子领域。（这也是我们最常用的策略）
				- 业务概念：捕捉目标系统中一目了然的业务概念，将其作为子领域。

- 6.架构映射阶段

	- 6.1 限界上下文的定义和特征

		- 6.1.1 限界上下文的定义

		  
		  限界上下文是语义和语境的边界。在问题空间，统一语言形成了团队对领域概念的统一表达，子领域形成了领域概念之间的边界。而在解空间，限界上下文可以看做是统一语言+子领域的融合体，统一语言需要在限界上下文内才具有明确的业务含义。
		  
		  以电商购物场景为例。在进行商品下单后，系统会生成一个订单；在用户付款完成后，系统也会生成一个订单；到了物流派送流程，系统还会生成一个订单。虽然这三个步骤中的领域概念都叫订单，但是他们的关注点/职责却不同：商品订单关注的是商品详情，支付订单关注的是支付金额和分润情况，物流订单关注的是收货地址。也就是说，商品、支付和物流分别为三个限界上下文，而订单作为统一语言需要在特定的限界上下文内，我们才能够明确其关注点/负责的职责。
		  
		  

		- 6.1.2 限界上下文的特征

			- 最小完备：限界上下文在履行属于自己的业务能力时，拥有的领域知识是完整的，无须针对自己的信息去求助别的限界上下文。
			- 自我履行：限界上下文能够根据自己拥有的知识来完成业务能力。自我履行体现了限界上下文纵向切分业务能力的特征。
			- 稳定空间：限界上下文必须防止和减少外部变化带来的影响。
			- 独立进化：指减少限界上下文内部变化对外界产生的影响。

	- 6.2 限界上下文的识别

		- 6.2.1 按业务维度识别

			- 1. 归类

				- 语义相关性：存在相同或相似的领域概念，对应于业务服务描述的名词，如果不同的业务服务操作了相同或相似的对象，即可认为它们存在语义相关性。
				- 功能相关性：体现领域行为的相关性，业务服务是否服务于同一个业务目标。

			- 2. 归纳

			  归纳是对归类后的限界上下文进行命名。给限界上下文命名的过程，实际上也是对归类是否合理的再一次复查。限界上下文的命名同样需要遵循单一职责原则，它只能代表唯一的最能体现其特征的领域概念。倘若归类不合理，命名就会变得困难，这时候我们就需要反思（遵循知识消化循环）归类是否合理，并重新设计归类。
			  

			- 3. 边界梳理

			  归类和归纳之后，限界上下文的边界基本已经确定，边界梳理则是根据限界上下文特征（最小完备、自我履行、稳定空间和独立进化）以及子领域进行微调（当然也不排除大调）。
			  

				- 为什么需要根据子领域进行限界上下文边界的调整？限界上下文和子领域的关系是什么？
				- 理想的限界上下文与子领域的关系是一一对应的。上文提到，子领域是领域专家根据领域经验选择合适的功能分类策略进行划分，这个过程不会牵扯对业务服务的分析，体现的是领域专家对行业的洞见和深刻认识，可见获取子领域是一个自顶向下的过程。而限界上下文则是对业务服务进行归类、归纳、梳理和调整，最终形成一个个的边界，这是一个自下而上的过程。理想情况下，两者应该是双向奔赴的，自顶向下得到的子领域和自下而上得到的限界上下文能够完美契合！但是，现实哪有这么理想呢！所以一般情况下都需要我们进行调整，力求这两者能够一一对应。
				- 这里就再cue一下知识消化循环。优秀的领域专家划分出来的子领域，往往能够实现与限界上下文的一一对应。这就是经验的力量！那经验是怎么来的呢？我认为是领域专家经历了无数个知识消化循环之后沉淀下来的。领域专家一开始也是小白，划分出来的子领域在映射为限界上下文之后发现不同限界之间可能存在语义重叠，角色在不同限界上下文之中履行的职责可能很相似，于是他们通过知识消化循环，不断调整限界上下文的边界，然后又通过限界上下文调整子领域。慢慢地，稳定、可复用的子领域就被沉淀下来了。因此，识别限界上下文不是一个单向的过程，而是一个根据子领域调整限界上下文，然后又根据限界上下文调整子领域的循环的过程。

		- 6.2.2 验证

			- 正交原则

				- 正交性：如果两个或更多事物中的一个发生变化，不会影响其他事物，这些事物就是正交的。要破坏变化的传递性，就要保证每个限界上下文对外提供的业务服务不能出现雷同。

			- 奥卡姆剃刀原理

				- “如无必要，勿增实体”。这是避免过度设计的良方，同样也是我们识别限界上下文的原则。如果对识别出来的限界上下文的准确性依然心存疑虑，比较务实的做法是保证限界上下文具备一定的粗粒度。遵循该原则，意味着当我们没有寻找到必须切分限界上下文的必要证据时，就不要增加新的限界上下文。

	- 6.3 上下文映射

	  
	  限界上下文封装了分离的业务能力，上下文映射则建立了限界上下文之间的关系。上下文映射提供了各种模式（防腐层、开放主机服务、发布语言、共享内核、合作者、客户方/供应方、分离方式、遵奉者、大泥球），本质是在控制变化在限界上下文之间传递所产生的影响。
	  
	  下文将提供服务的限界上下文称为“上游”上下文（U表示），消费服务的限界上下文称为“下游”上下文（D表示）。
	  
	  

		- 6.3.1 防腐层

			- 引入防腐层的目的是为了隔离耦合。防腐层往往位于下游，通过它隔离上游上下文发生的变化。

		- 6.3.2 开放主机服务（OHS）
		- 6.3.3 发布语言（PL）

		  
		  发布语言是一种公共语言，用于两个限界上下文之间的模型转换。防腐层和开放主机服务都是访问领域模型时建立的一层包装，前者针对发起调用的下游（通过基础设施层体现），后者针对响应请求的上游（通过应用层+远程服务），以避免上下游之间的通信集成将各自的领域模型引入进来，造成彼此之间的强耦合。因此，防腐层和开放主机服务操作的对象都不应该是各自的领域模型，这正是引入发布语言的原因。（对于熟悉云API的小伙伴就会发现，其实云API根据我们定义的接口生成对应的Request对象和Response对象，并集成在云API的SDK中，这些对象就是发布语言）。
		  
		  
		  一般情况下，发布语言根据开放主机服务的服务契约进行定义。
		  
		  
		  说到这里，我们惊讶地发现防腐层，开放主机服务和发布语言可以完美联动！
		  
		  

		- 6.3.4 共享内核

		  
		  共享内核指将限界上下文中的领域模型直接暴露给其他限界上下文使用。注意，这会削弱了限界上下文边界的控制力。上面我们讲述的防腐层、开放主机服务以及发布语言无不传达一种思想，限界上下文不能直接暴露自己的领域模型或直接访问其他限界上下文的领域模型，一定要有隔离层！
		  
		  但是，在特定的场景下，共享内核不见得不是一种合理的方式。任何软件设计决策都要考量成本与收益，只有收益高于成本，决策才是合理的。一般对于一些领域通用的值对象是相对稳定的，这些类型通常属于通用子领域，会被系统中几乎所有的限界上下文复用，那么这些领域模型就适合使用共享内核的方式。共享内核的收益不言而喻，而面临的风险则是共享的领域模型可能产生的变化。
		  
		  

		- 6.3.5 合作者

		  合作关系指的是协作的限界上下文由不同的团队负责，且这些团队之间具有要么一起成功，要么一起失败的强耦合关系。合作者模式要求参与的团队一起做计划、一起提交代码、一起开发和部署，采用持续集成的方式保证两个限界上下文的集成度与一致性，避免因为其中一个团队的修改影响集成点的失败。
		  

		- 6.3.6 客户方/供应方

		  
		  当一个限界上下文单向地为另一个限界上下文提供服务时，它们对应的团队就形成了客户方/供应方模式。这是最为常见的团队协作模式，客户方作为下游团队，供应方作为上游团队，二者协作的主要内容包括：
		  下游团队对上游团队提出的服务
		  上游团队提供的服务采用什么样的协议与调用方式
		  下游团队针对上游服务的测试策略
		  上游团队给下游团队承诺的交付日期
		  当上游服务的协议或调用方式发生变更时，如何控制变更
		  

		- 6.3.7 分离方式

		  分离方式的团队协作模式是指两个限界上下文之间没有一丁点关系。如果此时双方使用到了相似/相同的领域模型，则可以通过拷贝的方式解决，保证限界上下文之间的物理隔离！
		  

		- 6.3.8 遵奉者

		  
		  当上游的限界上下文处于强势地位，且上游团队响应不积极时，我们可以采用遵奉者模式。即下游严格遵从上游团队的模型，以消除复杂的转换逻辑。
		  
		  当下游团队选择“遵奉”于上游团队设计的模型时，意味着：
		  可以直接复用上游上下文的模型（好的）；
		  减少了两个限界上下文之间模型的转换成本（好的）；
		  使得下游限界上下文对上游产生了模型上的强依赖（坏的）。
		  

		- 6.3.9 大泥球

		  
		  一定要避免制造大泥球！大泥球的特点：
		  越来越多的聚合因为不合理的关联和依赖导致交叉污染；
		  对大泥球的维护牵一发而动全身；
		  强调“个人英雄主义”，只有个别“超人”能够理清逻辑。
		  

	- 6.4 示例-SMS的限界上下文及其映射

		- 成绩上下文
		- 课程上下文
		- 审批上下文
		- 权限上下文
		- 邮件上下文

- 7.领域建模阶段

  领域建模阶段由领域分析建模，领域设计建模和领域实现建模组成。在正式讲解建模活动前，先了解一下什么是模型驱动设计。
  

	- 7.1 模型驱动设计

	  
	  模型是一种知识形式，它对知识进行了选择性的简化和有意的结构化，从而解决信息超载的问题。模型便于人们理解信息的意义，并专注核心问题。
	  
	  
	  建模过程一般由分析活动、设计活动和实现活动组成。每一次建模活动都是一次对知识的提炼和转换，并产生相应的模型，即分析模型、设计模型和实现模型。
	  
	  
	  建模过程并非是分析、设计和实现单向的前后串行过程，而是相互影响，不断切换和递进的关系。模型驱动设计的建模过程是：分析中蕴含了设计，设计中夹带了实现，甚至实现后还要回溯到设计和分析的一种迭代的、螺旋上升的演进过程。
	  
	  
	  根据分解问题的视角不同，我们日常建立的模型可以大致分为以下三类：
	  
	  数据模型：将问题空间抽取出来的概念视为数据信息，在求解过程中关注数据实体的样式和它们之间的关系，由此建立的模型就是数据模型。
	  服务模型：将每个问题视为目标系统为客户端提供的服务，在求解过程就会关注客户端发起的请求以及服务返回的响应，由此建立的模型就是服务模型。
	  领域模型：围绕问题空间的业务需求，在求解过程中力求提炼出表达领域知识的逻辑概念，由此建立的模型就是领域模型。
	  

		- 7.1.1 领域模型驱动设计

		  
		  一个优秀的领域模型应该具备以下的特征（我们也可以说具备这些特征的模型就是领域模型）：
		  
		  运用统一语言来表达领域中的概念；
		  蕴含业务活动和规则等领域知识；
		  对领域知识进行适度的提炼和抽象；
		  由一个迭代的演进过程建立；
		  有助于产品、领域专家和开发同学进行交流。
		  
		  领域建模阶段目的便是建立领域模型。领域模型由领域分析模型、领域设计模型以及领域实现模型共同组成，它们也分别是领域分析建模、领域设计建模和领域实现建模三个建模活动的产物。
		  
		  
		  值得注意的是，领域模型并非由开发团队单方面输出的产物，而是由产品、领域专家和开发团队共同协作的结果。领域专家通过领域模型能够判断系统所支持的领域能力，以及由此编排出来的上层业务能力；开发团队通过领域模型能够形成基本的代码框架（包括架构分层，每层需要定义的接口，接口的命名等）。同理，领域模型的调整，也意味着领域知识或业务规则的变化，也预示着系统所支持的业务能力和代码实现同样需要作出改变。
		  
		  

	- 7.2 领域分析建模

	  
	  领域分析建模：在限界上下文内，以“领域”为中心，提炼业务服务中的领域概念，确定领域概念之间的关系，最终形成领域分析模型。领域分析模型描述了各个限界上下文中的领域概念，以及领域概念之间的关系。
	  
	  下面讲述如何通过“快速建模法”来构建领域分析模型。
	  

		- 7.2.1 名词建模
		- 7.2.2 动词建模

		  
		  识别动词并不是为领域模型对象分配职责、定义方法，而是将识别出来的动词当做一个领域行为，然后看它是否产生了影响管理、法律或财务的过程数据。若存在，则将这些过程数据作为领域概念放到领域分析模型中。注意，这里的过程数据是要求会对企业运营和管理产生影响的数据，比如示例-SMS系统中老师提交修改申请，就会产生申请单这个过程数据，而请求流水记录、任务执行记录都不属于过程数据。
		  动词建模通过分析领域行为是否产生过程数据来找到隐藏的领域概念，弥补了名词建模的不足。
		  
		  
		  特别地，对于会产生领域事件的动词，一般可以抽象出一个已完成该动作的状态。
		  
		  

		- 7.2.3 提取隐式概念
		- 7.2.4 归纳抽象

		  
		  对于有定语修饰的名词，要注意分辨它们是类型的差异，还是值的差异。如配送地址和家庭地址，订单状态和商品状态。如果是值的差异，类型相同，应归并为一个领域概念（如，配送地址和家庭地址）；而类型不同，则不能合并（如，订单状态和商品状态）。
		  
		  
		  特别地，当定语修饰的名词中，定语表示的是不同的限界上下文，且名词相同时（即名称相同、含义不同的领域概念），我们应该尽可能调整命名，确保含义不同的领域概念的名称不同，以避免不必要的歧义和沟通上的误解。比如：商品的订单和库存的订单在特定限界上下文内都可以命名为order，但是如果把库存的订单改为库存的配送单delivery效果会更好。
		  
		  
		  

		- 7.2.5 确认关系

		  
		  根据业务需求和领域知识，判断领域概念之间是否存在关联。且对于1:N, N:1, M:N的关联关系，我们需要判断是否可以为这些关联关系定义一个新的类型，比如作品与读者存在1:N的关系，我们可以定义“订阅”这个概念来描述这种关系。
		  
		  
		  注意，我们需要尽量避免对象中的双向关系，即对象A关联对象B，而对象B关联对象A。当两个对象存在双向关系时，会为管理他们的生命周期带来额外的复杂度。我们应该规定一个遍历方向，来表明一个方向的关联比另一个方向的关联更有意义且更重要，比如示例SMS中，成绩会关联课程（成绩实例中包含课程ID），而课程不会关联成绩。当然，当双向关系是领域的一个概念时，我们还是应该保留它。
		  
		  

		- 7.2.6 示例-SMS的领域分析模型

		  通过名词建模，动词建模和归纳抽象后，可提炼出以下领域对象：成绩（Result）、绩点（gpa）、总成绩（total result）、总绩点（total gpa）、学年（school year）、学期（semester）、课程（course）、学分（credit）、申请单（application receipt），邮件（mail），排名（rank），申请单状态（application receipt status）
		  

	- 7.3 领域设计建模

		- 7.3.1 设计要素

		  
		  领域驱动设计强调以“领域”为核心驱动力。设计领域模型时应该尽量避免陷入到技术实现的细节约束中。但很多时候我们又不得不去思考一些非领域相关的问题：
		  
		  领域模型对象在身份上是否存在明确的差别？
		  领域模型对象的加载以及对象间的关系如何处理？
		  领域模型对象如何实现数据的持久化？
		  领域模型对象彼此之间如何做到弱依赖地完成状态的变更通知？
		  
		  为了解答上述的四个问题，DDD提供了很多的设计要素，它们能够帮助我们在不陷入到具体技术细节的情况下进行领域模型的设计。
		  
		  

			- 7.3.1.1 实体
			- 7.3.1.2 值对象
			- 7.3.1.3 聚合

			  
			  聚合的基本特征：
			  
			  聚合是包含了实体和值对象的一个边界。
			  聚合内包含的实体和值对象形成一棵树，只有实体才能作为这棵树的根。
			  外部对象只允许持有聚合根的引用，以起到边界控制作用。
			  聚合作为一个完整的领域概念整体，其内部会维护这个领域概念的完整性。
			  由聚合根统一对外提供履行该领域概念职责的行为方法，实现内部各个对象之间的行为协作。
			  

			- 7.3.1.4 工厂

			  
			  聚合中的工厂：一个类或方法只要封装了聚合对象的创建逻辑，都可以认为是工厂。表现形式如下：
			  
			  引入专门的聚合工厂（尤其适合需要通过访问外部资源来完成创建的复杂创建逻辑）
			  聚合自身担任工厂（简单工厂模式）
			  服务契约对象或装配器（assembler）担任工厂（负责将外部请求对象DTO转换为实体）
			  使用构建者组装聚合
			  
			  注意！这里工厂创建的基本单元是聚合，而非实体，注意与实体中的创建行为区分。
			  
			  

			- 7.3.1.5 资源库

			  
			  资源库是对数据访问的一种业务抽象，用于解耦领域层与外部环境，使领域层变得更为纯粹。资源库可以代表任何可以获取资源的仓库，例如网络或其他硬件环境，而不局限于数据库。
			  
			  
			  一个聚合对应一个资源库。领域驱动设计引入资源库，主要目的是管理聚合的生命周期。资源库负责聚合记录的查询与状态变更，即“增删改查”操作。资源库分离了聚合的领域行为和持久化行为，保证了领域模型对象的业务纯粹性。
			  
			  
			  值得注意的是，资源库的操作单元是聚合。当我们定义资源库的接口时，接口的入参应该为聚合的根实体。如果要访问聚合内的非根实体，也只能通过资源库获得整个聚合后，将根实体作为入口，在内存中访问封装在聚合边界内的非根实体对象。
			  
			  

			- 7.3.1.6 领域服务

			  
			  聚合通过聚合根的领域行为对外提供服务，而领域服务则是对聚合根的领域行为的补充。因此，我们应该尽量优先通过聚合根的领域行为来满足业务服务。
			  
			  
			  那什么场景下我们会需要用到领域服务呢？有如下两个：
			  
			  生命周期管理。为了避免领域知识的泄露，应用服务不会直接引用聚合生命周期相关的服务（工厂、资源库接口），而聚合根实体一般不会依赖资源库接口，此时就需要领域服务进行组合对外暴露。
			  依赖外部资源。为了保证聚合的稳定性，聚合根实体不会依赖防腐层接口。因此，当聚合对外暴露的服务需要设计外部资源访问时，就需要通过领域服务来完成。
			  

			- 7.3.1.7 领域事件

			  
			  领域事件属于领域层的领域模型对象，由限界上下文中的聚合发布，感兴趣的聚合（同一限界上下文/不同限界上下文）可以进行消费。而当一个事件由应用层发布，则该事件为应用事件。
			  
			  
			  引入领域事件首要目的是更好地跟踪实体状态的变更，并在状态变更时，通过事件消息的通知完成领域模型对象之间的协作。
			  
			  
			  领域事件的特征：
			  
			  领域事件代表了领域的概念；
			  领域事件是已经发生的事实（表示事件的名称应该是过去时，比如Committed）；
			  领域事件是不可变的领域对象；
			  领域事件会基于某个条件而触发。
			  
			  领域事件的用途：
			  
			  发布状态变更；
			  发布业务流程中的阶段性成果；
			  异步通信。
			  
			  领域事件应该包含：
			  
			  身份标识，即事件ID，为通用类型的身份标识；
			  事件发生的时间戳，便于记录和跟踪；
			  属性需要针对订阅者的需求，在增强事件和反向查询之间进行权衡。增强事件指属性中包含订阅者所需的所有数据；反向查询则是属性包含事件ID，当订阅者需要数据时通过事件ID进行反向查询。
			  

		- 7.3.2 设计聚合

			- 7.3.2.1 设计的经验法则
			- 7.3.2.2 设计步骤

				- 1. 理顺对象图

				  聚合本质是一个高内聚的边界，因此我们可以根据领域对象之间关系的强弱来定义出聚合的边界。对象间的关系由强到弱可以分为：泛化关系，关联关系和依赖关系。其中关联关系和依赖关系在 7.3.2.1 小节已讲述，而泛化关系可以理解为是继承关系（即父子关系）。
				  

					- 泛化关系

					  
					  虽然泛化关系是强耦合关系，但是根据对业务理解的视角不同，会产生不同的设计：
					  
					  整体视角：调用者并不关心特化的子类之间的差异，而是将整个继承体系视为一个整体。此时应以泛化的父类作为聚合根。
					  独立视角：调用这只关注具体的特化子类，体现了概念的独立性，此时应以特化的子类作为独立的聚合根。
					  

					- 关联关系

					  
					  关联关系
					  
					  
					  上述提到过，聚合间的关联关系会涉及聚合A对聚合B的生命周期管理，这其实是一个比较宽松的约束。那聚合内实体的关联关系应该是怎么样的呢？生命周期一致的、共存亡的，当主实体被销毁时，从实体也随之会被销毁。比如商品实体和商品明细实体。而在示例-SMS中，成绩和总成绩会被定义为两个聚合，原因是总成绩在成绩锁定后被统计，随后将不再发生改变，可见两者不存在上述的共存亡的关联关系。
					  
					  
					  PS: 实际上根据关联关系来区分边界的方法同样适用于限界上下文的边界划分。比如示例-SMS中的课程和成绩生命周期不同，先有课程，后有成绩；而且成绩锁定后，课程被撤销也不会对成绩有影响，因此就可以定义出课程上下文和成绩上下问。
					  
					  

					- 依赖关系

					  
					  依赖关系
					  
					  依赖关系主要体现的是实体间的职责委派和创建行为，可以分到不同的聚合边界。
					  
					  

		- 7.3.3 设计服务

		  这里的服务是对应用服务、领域服务、领域行为（实体提供的方法）和端口（资源库接口、防腐层接口）的统称。
		  

			- 7.3.3.1 分解任务

			  业务服务包含若干个组合服务，组合服务包含若干个原子服务。领域行为和端口都可以认为是原子服务。
			  

			- 7.3.3.2 分配职责

			  
			  应用服务：匹配业务服务，提供满足业务需求的服务接口。应用服务自身并不包含任何领域逻辑，仅负责协调领域模型对象，通过它们的领域能力组合完整一个完整的应用目标。
			  
			  
			  领域服务：匹配组合服务，执行业务功能，若原子任务为无状态行为或独立变化的行为，也可以匹配领域服务。控制多个聚合与端口之间的协作，由它来承担组合任务的执行。
			  
			  
			  领域行为：匹配原子服务，提供业务功能的业务实现。强调无状态和独立变化，由实体提供。
			  
			  
			  端口：匹配原子服务，抽象对外资源的访问，主要的端口包括资源库接口和防腐层接口。
			  
			  

		- 7.3.4 示例-SMS的领域设计模型

	- 7.4 领域实现建模

	  领域实现建模关注的并非是如何进行代码实现，而是如何验证代码实现的正确性，保证实现的高质量。
	  

		- 7.4.1 领域模型与测试金字塔

		  领域模型中的服务包括了应用服务、领域服务、领域行为和端口。其中通过Provider（面向服务行为）、Resource（面向服务资源）、Subscriber（面向事件）、Controller（面向视图模型）对外进行暴露的，我们称为远程服务。
		  

		- 7.4.2 测试驱动开发

		  
		  领域实现建模提倡的是测试驱动开发的编程思想，即要求开发者在进行逻辑实现前，优先进行测试用例的编写，站在调用者角度而非实现者角度去思考接口。
		  
		  
		  在上述测试金字塔中，开发者需要关注的是单元测试（不依赖任何外部资源的测试就是单元测试）。在领域设计建模阶段，我们对业务服务/应用服务进行分解，定义出了领域行为和领域服务。对于领域行为，由于其不依赖外部资源，因此我们可以直接编写单元测试；而对于领域服务，其可能会通过端口访问外部资源，此时我们需要对端口进行mock，以隔离外部资源对领域逻辑验证的干扰。特别地，单元测试一定要覆盖所有对业务规则的验证，这是保证领域行为和领域服务正确性的基础。
		  
		  
		  单元测试编码规范：
		  
		  测试类的命名应与被测试类保持一致，为“被测类名称+Test后缀”。
		  测试方法表达业务或业务规则为目的。
		  测试方法体遵循Given-When-Then模式。Given: 为要测试的方法提供准备，包括创建被测试对象，为调用方法准备输入参数实参等；When: 调用被测试的方法，遵循单一职责原则，在一个测试方法的When部分，应该只有一条语句对被测方法进行调用；Then: 对被测方法调用后的结果进行预期验证。
		  

- 8.分层架构与代码骨架

	- 8.1 分层架构

	  
	  代码架构分层是经典DDD四层：用户接口层，应用层，领域层和基础设施层。
	  
	  
	  需要注意的的地方是：
	  
	  用户接口层根据通信方式的不同，区分开了Provider（面向服务行为）、Subscriber（面向事件）、Controller（面向视图模型&资源） 、Task（面向策略/定时任务）。
	  基础设施层单独划分了 infranstructure-impl模块。为了保证领域层的纯洁性，DDD通过依赖倒置把访问外部系统（数据库，第三方系统）的服务的实现都下放到了基础设施层，而 infranstructure-impl模块 则是对这些实现进行了归集。这样做的好处有两个：第一，依赖关系明确，（infransturcture-impl —> domain，application）, （interface、application、domain —> infranstructure）；第二，拆分服务更便捷。当我们需要部分领域独立拆分出来的时候，在实现层面就只需要关注 infransturcture-impl模块 即可。
	  Infranstructure-impl模块依赖应用层的原因是应用层可能会抽象出防腐层接口，需要infranstruct-impl为其提供实现。
	  

	- 8.2 代码骨架

		- 8.2.1 用户接口层
		- 8.2.2 应用层
		- 8.2.3 领域层
		- 8.2.4 基础设施实现层

- 9.杂谈

	- 9.1 DDD与微服务

	  
	  微服务拆解指的是把一个单体服务拆分为粒度“足够小”的多个服务，而这里的“足够小”是一个主观的，没有任何标准的定义。尽管如此，我们对“微”这个词还是有一些基本要求的：足够内聚，足够独立，足够完备，这才使得拆分出来的微服务收益大于投入，试想如果一个微服务提供的业务功能会牵扯到与其他众多微服务的协作，那岂不是芭比Q了。
	  
	  
	  而上述我们对微服务的基本要求，实际上与限界上下文的特征（最小完备，自我履行，稳定空间，独立进化）不谋而合，因此，我们可以把限界上下文映射为微服务。我在日常实践中，都是将限界上下文和微服务的关系进行一一对应的，但这不是绝对的！限界上下文是站在领域角度给出的逻辑边界，而微服务的设计往往还要考虑物理边界，以及实际的质量需求（性能，可用性，安全性等），比如当我们采用的是CQRS架构，领域模型会被分为命令模型和查询模型，虽然它们同属一个限界上下文，但是它们往往是物理隔离的。因此，限界上下文只能作为微服务拆分的指导，而拆分过程中需要考虑质量需求，架构设计等技术因素。
	  
	  

	- 9.2 事务

		- 9.2.1 本地事务
		- 9.2.2 Saga事务

- 10. 参考

### 2. 千万同时在线直播聊天室架构演进

- 聊天室概述

	- 1500w在线的挑战

- 聊天室1.0架构

	- 消息框架选型：读扩散
	- longpolling机制
	- 无状态cache的设计

- 聊天室2.0架构

	- 分布式在线统计
	- 流量隔离vipsect
	- 自动柔性下的流量把控

- 成果

### 3. 聚焦！分布式唯一 ID 生成方案

- 1. 分布式唯一 ID 特性
- 2. 常用分布式唯一 ID 生成方案

	- 2.1. UUID
	- 2.2. 数据库自增 ID
	- 2.3. Redis 生成 ID
	- 2.4. Zookeeper 生成 ID
	- 2.5. Snowflake 算法

- 3. 数据库号段模式

	- 3.1. 号段模式介绍
	- 3.2. 美团 Leaf-segment 方案
	- 3.3. 滴滴 Tingid 方案
	- 3.4. 微信序列号生成方案

- 4. 雪花模式

	- 4.1. 雪花模式介绍
	- 4.2. 美团 Leaf-snowflake 方案
	- 4.3. 百度 UidGenerator 方案
	- 4.4. 基于多时间线改进的雪花算法

### 4. 后台服务架构高性能设计之道

- 前言
- 1 无锁化

	- 1.1 串行无锁
	- 1.2 结构无锁

- 2 零拷贝

	- 2.1 内存映射
	- 2.2 零拷贝

- 3 序列化

	- 3.1 分类
	- 3.2 性能指标
	- 3.3 选型考量

		- 1）性能：CPU 和字节占用大小是序列化的主要开销。在基础的 RPC 通信、存储系统和高并发业务上应该选择高性能高压缩的二进制序列化。一些内部服务、请求较少 Web 的应用可以采用文本的 JSON，浏览器直接内置支持 JSON。
		- 2）易用性：丰富数据结构和辅助工具能提高易用性，减少业务代码的开发量。现在很多序列化框架都支持 List、Map 等多种结构和可读的打印。
		- 3）通用性：现代的服务往往涉及多语言、多平台，能否支持跨平台跨语言的互通是序列化选型的基本条件。
		- 4）兼容性：现代的服务都是快速迭代和升级，一个好的序列化框架应该有良好的向前兼容性，支持字段的增减和修改等。
		- 5）扩展性：序列化框架能否低门槛的支持自定义的格式有时候也是一个比较重要的考虑因素。

- 4 池子化

	- 4.1 内存池
	- 4.2 线程池
	- 4.3 连接池
	- 4.4 对象池

- 5 并发化

	- 5.1 请求并发
	- 5.2 冗余请求

- 6 异步化

	- 6.1 调用异步化
	- 6.2 流程异步化

- 7 缓存

	- 7.1 缓存的使用场景
	- 7.2 缓存的分类
	- 7.3 缓存的模式
	- 7.4 缓存的回收策略
	- 7.5 缓存的崩溃与修复
	- 7.6 缓存的一些好实践

- 8 分片

	- 8.1 分片策略
	- 8.2 二级索引
	- 8.3 路由策略
	- 8.4 动态平衡
	- 8.5 分库分表
	- 8.6 任务分片

- 9 存储

	- 9.1 读写分离
	- 9.2 动静分离
	- 9.3 冷热分离
	- 9.4 重写轻读
	- 9.5 数据异构

- 10 队列

	- 10.1 应用场景
	- 10.2 应用分类

- 总结

### 5. 万字详文：腾讯高可用、高性能 ZooKeeper 源码和实践揭秘

### 6. 万字详文：Java内存泄漏、性能优化、宕机死锁的N种姿势

- 导读
- 内存泄漏

	- 堆上内存泄漏

		- 对象被静态对象引用
		- RPC连接使用完后未关闭

	- 堆外内存泄露

		- Java使用堆外内存
		- Java调用C++组件

- 性能优化

	- arthas
	- jaeger
	- tcpdump
	- jstack

- 宕机

	- 被其他进程杀
	- 调用System的exit
	- Java调用的C++发生Crash
	- Java内Crash

- 死锁

	- log4j导致的死锁
	- 封装不严谨导致的死锁

### 7. 叮～ 你有一封300+页的腾讯技术精华电子书，请查收

### 8. 万字详文：腾讯万级K8s集群背后etcd稳定性及性能优化实践

### 9. 腾讯万亿级 Elasticsearch 内存效率提升技术解密

- 前置知识

	- 1. ES
	- 2. JVM堆内存

	- 3. 零拷贝

	- 4. FST

	- 5. LRU

	- 6. 弱引用

- 1. 问题：日志分析场景数据量大，ES 内存瓶颈导致存储成本较高
- 2. 分析：成本瓶颈在哪里：堆内存使用率过高
- 3. 堆内存使用率为什么会高？

	- 1. 运营侧调整装箱策略能否解决问题？
	- 2. 堆内存被什么数据占用了？

- 4. 方案：降低 FST 堆内存占用量

	- 什么是 FST ？
	- 解决方案一：降低 FST 在堆内的内存使用量
	- 解决方案二：将 FST 从堆内存（OnHeap）移到堆外内存（OffHeap）

- 5. 实现：全链路 0 拷贝 FST OffHeap Cache

	- 总体架构
	- 全链路零拷贝 OffHeap FST 访问逻辑
	- 多级 Cache 将性能优化到极致

- 6. 其他优化点
- 7. 优化效果

	- 压测效果
	- 线上效果

## 哔哩哔哩技术团队

### 1. 2021.07.13 我们是这样崩的

- 1. 至暗时刻

	- SRE运维工程师

		- 可观测性系统
		- 故障响应
		- 故障复盘
		- 测试与发布
		- 容量规划
		- 自动化工具开发
		- 用户体验

- 2. 初因定位

	- 1. 无法登陆内网鉴权系统
	- 2. 在线业务主机房七层SLB（基于OpenResty构建） CPU 100%

		- 1. 什么是七层SLB？

		- 2. 为什么选择OpenResty?
		- 7层负载均衡与4层负载均衡区别

- 3. 故障止损

	- 1. 先Reload SLB未恢复后尝试拒绝用户流量冷重启SLB，冷重启后CPU依然100%，未恢复
	- 2. 准备重启多活机房SLB先尝试止损
	- 3. 此时尝试恢复主机房的SLB
	- 4. 新建源站SLB

		- 1. 决定重建一组全新的SLB集群
		- 2. SLB新集群初始化完成，开始配置四层LB和公网IP

	- 5. 恢复SLB

		- 1. Lua 程序分析工具
		- 2. CPU 热点明显集中在对 lua-resty-balancer 模块的调用
		- 3. 在热点的函数内添加 debug 日志
		- 4. _gcd 函数在某次执行后返回了一个预期外的值：nan

- 4. 根因定位

	- 1. 在服务的某种特殊发布模式中，会出现容器实例权重为0的情况
	- 2. 全局关闭 jit 编译
	- 3. LB运维修改SLB 集群的配置，关闭 jit 编译并分批重启进程，SLB CPU 全部恢复正常，可正常处理请求
	- 4. 平台禁止此发布模，SLB 先忽略注册中心返回的权重，强制指定权重。
	- 5. SLB 修改Lua代码忽略注册中心返回的权重。

- 5. 原因说明

	- 背景

	  B站在19年9月份从Tengine迁移到了OpenResty，基于其丰富的Lua能力开发了一个服务发现模块，从我们自研的注册中心同步服务注册信息到Nginx共享内存中，SLB在请求转发时，通过Lua从共享内存中选择节点处理请求，用到了OpenResty的lua-resty-balancer模块。到发生故障时已稳定运行快两年时间。
	  
	  在故障发生的前两个月，有业务提出想通过服务在注册中心的权重变更来实现SLB的动态调权，从而实现更精细的灰度能力。SLB团队评估了此需求后认为可以支持，开发完成后灰度上线。
	  

		- Tengine

		- OpenResty

	- 诱因

		- 1. 在某种发布模式中，应用的实例权重会短暂的调整为0
		- 2. balancer 模块中的 _gcd 函数收到的入参 b 可能为 "0"

	- 根因

		- Lua

		- _gcd函数

- 6. 问题分析

	- 1. 为何故障刚发生时无法登陆内网后台？

		- 事后我们梳理了办公网系统的访问链路，跟用户链路隔离开，办公网链路不再依赖用户访问链路。

	- 2. 为何多活SLB在故障开始阶段也不可用？

	  多活SLB在故障时因CDN流量回源重试和用户重试，流量突增4倍以上，连接数突增100倍到1000W级别，导致这组SLB过载。后因流量下降和重启，逐渐恢复。此SLB集群日常晚高峰CPU使用率30%左右，剩余Buffer不足两倍。如果多活SLB容量充足，理论上可承载住突发流量， 多活业务可立即恢复正常。此处也可以看到，在发生机房级别故障时，多活是业务容灾止损最快的方案，这也是故障后我们重点投入治理的一个方向。
	  

	- 3. 为何在回滚SLB变更无效后才选择新建源站切量，而不是并行？
	- 4. 为何新建源站切流耗时这么久？
	- 5. 后续根因定位后证明关闭jit编译并没有解决问题，那当晚故障的SLB是如何恢复的？

- 7. 优化改进

	-  1. 多活建设

	  在23:23时，做了多活的业务核心功能基本恢复正常，如APP推荐、APP播放、评论&弹幕拉取、动态、追番、影视等。故障时直播业务也做了多活，但当晚没及时恢复的原因是：直播移动端首页接口虽然实现了多活，但没配置多机房调度。导致在主机房SLB不可用时直播APP首页一直打不开，非常可惜。通过这次事故，我们发现了多活架构存在的一些严重问题：
	  

		- 多活基架能力不足
		- 业务多活元信息缺乏平台管理
		- 多活切量容灾能力薄弱
		- 多活基架能力建设
		- 多活管控能力提升

	-  2. SLB治理

		- 架构治理

		  故障前一个机房内一套SLB统一对外提供代理服务，导致故障域无法隔离。后续SLB需按业务部门拆分集群，核心业务部门独立SLB集群和公网IP。
		  
		  跟CDN团队、四层LB&网络团队一起讨论确定SLB集群和公网IP隔离的管理方案。
		  
		  明确SLB能力边界，非SLB必备能力，统一下沉到API Gateway，SLB组件和平台均不再支持，如动态权重的灰度能力。
		  
		  

		- 运维能力

		  SLB管理平台实现Lua代码版本化管理，平台支持版本升级和快速回滚。
		  
		  SLB节点的环境和配置初始化托管到平台，联动四层LB的API，在SLB平台上实现四层LB申请、公网IP申请、节点上线等操作，做到全流程初始化5分钟以内。
		  
		  SLB作为核心服务中的核心，在目前没有弹性扩容的能力下，30%的使用率较高，需要扩容把CPU降低到15%左右。
		  
		  优化CDN回源超时时间，降低SLB在极端故障场景下连接数。同时对连接数做极限性能压测。
		  
		  

		- 自研能力

		  运维团队做项目有个弊端，开发完成自测没问题后就开始灰度上线，没有专业的测试团队介入。此组件太过核心，需要引入基础组件测试团队，对SLB输入参数做完整的异常测试。
		  
		  跟社区一起，Review使用到的OpenResty核心开源库源代码，消除其他风险。基于Lua已有特性和缺陷，提升我们Lua代码的鲁棒性，比如变量类型判断、强制转换等。
		  
		  招专业做LB的人。我们选择基于Lua开发是因为Lua简单易上手，社区有类似成功案例。团队并没有资深做Nginx组件开发的同学，也没有做C/C++开发的同学。
		  
		  

	-  3. 故障演练

	  本次事故中，业务多活流量调度、新建源站速度、CDN切量速度&回源超时机制均不符合预期。所以后续要探索机房级别的故障演练方案：
	  
	  模拟CDN回源单机房故障，跟业务研发和测试一起，通过双端上的业务真实表现来验收多活业务的容灾效果，提前优化业务多活不符合预期的隐患。
	  
	  灰度特定用户流量到演练的CDN节点，在CDN节点模拟源站故障，观察CDN和源站的容灾效果。
	  
	  模拟单机房故障，通过多活管控平台，演练业务的多活切量止损预案。
	  

	- 4. 应急响应

		- NOC技术支持工程师

- 8. 总结

## DataFunTalk

### 分布式存储系统Apache HBase的现状和发展

- ＨBase是什么

	- 1.HBase的四大基因

		- （1）自动分区
		- （2） LSM-Tree
		- （3）存储计算分离
		- （4）ＨBase生态

	- 2.场景
	- 3.使用HBase的商业公司
	- 4.HBase特性总结

- ＨBase社区的发展

	- 1.HBase的起源
	- 2.HBase项目现状
	- 3.HBase目前版本

- ＨBase2.0

	- 1. HBase2.0版本发布历史
	- 2. 新功能

		- （1）Region Replica
		- （2）读写链路Off-heap
		- （3）In Memory Compaction
		- （4）小对象存储MOB
		- （5）Assignment MangerV2
		- （6）其他

	- 3.兼容性和升级建议

- ＨBase未来规划

	- 1. HBaseConAsia & 开发者圆桌会议
	- 2. 更加易用
	- 3. 更高性能
	- 4.更强扩展性和稳定性

- 如何成为Committer

### 蚂蚁超大规模商家知识图谱构建及其融合应用

- 商家图谱概览

	- 1. 背景介绍
	- 2. 体系建设

- 图谱构建&融合

	- 1. 图谱构建

		- ① 整体框架

			- 数据源

				- MaxCompute

				- 半结构化数据

			- 知识建模

				- 概念域-实体域-事件域

			- 知识加工
			- 知识存储
			- 知识运营
			- 持续学习

		- ② 知识获取-文本分类
		- ③ 知识获取-文本抽取
		- ④ 知识链指

	- 2. 图谱融合
	- 3. 图谱认知

- 图谱开放

	- 1. 开放知识
	- 2. 开放SDK能力

- 总结

### 吴维伟：京东零售大数据云原生平台化实践

- 京东数据平台架构简介
- 跨域存储

	- 1. 跨域存储——问题
	- 2. 跨域存储——架构
	- 3. 跨域存储——跨域数据流
	- 4. 跨域存储——拓扑与机房感知
	- 5. 跨域存储——跨域标识
	- 6. 跨域存储——跨域补块及流控

- 分层存储

	- 1. 分层存储——问题
	- 2. 分层存储
	- 3. 分层存储——使用场景
	- 4. 分层存储——架构
	- 5. 分层存储——核心设计

### 张鸿志：美团大脑百亿级知识图谱的构建及应用进展

- “美团大脑”简介
- 标签图谱构建及应用
- 菜品知识图谱构建技术

### 陈宏智：字节跳动自研万亿级图数据库ByteGraph及其应用与挑战

- 了解图数据库
- 适用场景介绍举例
- 数据模型和查询语言
- ByteGraph架构与实现
- 关键问题分析

### 实时数据湖在字节跳动的实践

- 对实时数据湖的解读
- 在落地实时数据湖的过程中遇到的一些挑战和应对方式
- 结合场景介绍实时数据湖在字节内部的一些实践案例
- 数据湖发展的一些规划

### 大数据在车联网行业的实践与应用

- 车联网平台
- 数据存储
- 数据接入
- 数据应用

### 阿里巴巴双十一千万级实时监控系统技术揭秘

### 个性化推荐技术分析，以淘宝为例

### 各公司用户画像技术案例分享

## 网络文章

### 1. 深入浅出 HTTPS (详解版)

- 今日头条链接

- HTTP 概述

	- HTTP 是什么？
	- HTTP 发展史

		- 创世纪
		- HTTP/0.9
		- HTTP/1.0
		- TTP/1.1
		- HTTP/2
		- HTTP/3

	- 与 HTTP 相关的各种概念和协议

		- 浏览器
		- Web 服务器
		- TCP/IP
		- DNS
		- URI/URL
		- CDN
		- HTTPS
		- 代理
		- 小结

	- 总结

- SSL/TLS

  SSL/TLS是位于TCP/IP 7层协议中的会话层，用于认证用户和服务器，加解密数据以及维护数据的完整性，确保数据在传输过程中不会被修改。
  
  SSL 有 v2 和 v3 两个版本，而 v1 因为有严重的缺陷从未公开过。SSL 发展到 v3 时已经证明了它自身是一个非常好的安全通信协议，于是互联网工程组 IETF 在 1999 年把它改名为 TLS（传输层安全，Transport Layer Security），正式标准化，版本号从 1.0 重新算起，所以 TLS1.0 实际上就是 SSLv3.1。
  
  到今天 TLS 已经发展出了三个版本，分别是 2006 年的 1.1、2008 年的 1.2 和去年（2018）的 1.3，每个新版本都紧跟密码学的发展和互联网的现状，持续强化安全和性能，已经成为了信息安全领域中的权威标准。
  
  目前应用的最广泛的 TLS 是 1.2，而之前的协议（TLS1.1/1.0、SSLv3/v2）都已经被认为是不安全的，各大浏览器即将在 2020 年左右停止支持，所以接下来的讲解都针对的是 TLS1.2。
  
  TLS 由记录协议、握手协议、警告协议、变更密码规范协议、扩展协议等几个子协议组成，综合使用了对称加密、非对称加密、身份认证等许多密码学前沿技术。浏览器和服务器在使用 TLS 建立连接时需要选择一组恰当的加密算法来实现安全通信，这些算法的组合被称为“密码套件”（cipher suite，也叫加密套件）。
  
  SSL/TLS分为对称加密和非对称加密两种方式。
  

- 对称加密

	- 对称加密是指加密和解密都用同一份密钥。

- 非对称加密

	- 非对称加密对应于一对密钥，称为私钥和公钥，用私钥加密后需要用公钥解密，用公钥加密后需要用私钥解密。
	- 对称加密的优点是运算速度快，缺点是互联网环境下无法将密钥安全的传送给对方。非对称加密的优点是可以安全的将公钥传递给对方，但是运算速度慢。

- 数字签名与证书

  
  黑客虽然拿不到会话密钥，无法破解密文，但可以通过窃听收集到足够多的密文，再尝试着修改、重组后发给网站。因为没有完整性保证，服务器只能“照单全收”，然后他就可以通过服务器的响应获取进一步的线索，最终就会破解出明文。
  
  另外，黑客也可以伪造身份发布公钥。如果你拿到了假的公钥，混合加密就完全失效了。你以为自己是在和“某宝”通信，实际上网线的另一端却是黑客，银行卡号、密码等敏感信息就在“安全”的通信过程中被窃取了。
  
  
  所以，在机密性的基础上还必须加上完整性、身份认证等特性，才能实现真正的安全。
  
  
  

- 摘要算法

  
  实现完整性的手段主要是摘要算法（Digest Algorithm），也就是常说的散列函数、哈希函数（Hash Function）。
  
  你可以把摘要算法近似地理解成一种特殊的压缩算法，它能够把任意长度的数据“压缩”成固定长度、而且独一无二的“摘要”字符串，就好像是给这段数据生成了一个数字“指纹”。
  
  换一个角度，也可以把摘要算法理解成特殊的“单向”加密算法，它只有算法，没有密钥，加密后的数据无法解密，不能从摘要逆推出原文。
  
  摘要算法实际上是把数据从一个“大空间”映射到了“小空间”，所以就存在“冲突”（collision，也叫碰撞）的可能性，就如同现实中的指纹一样，可能会有两份不同的原文对应相同的摘要。好的摘要算法必须能够“抵抗冲突”，让这种可能性尽量地小。
  
  因为摘要算法对输入具有“单向性”和“雪崩效应”，输入的微小不同会导致输出的剧烈变化，所以也被 TLS 用来生成伪随机数（PRF，pseudo random function）。
  
  你一定在日常工作中听过、或者用过 MD5（Message-Digest 5）、SHA-1（Secure Hash Algorithm 1），它们就是最常用的两个摘要算法，能够生成 16 字节和 20 字节长度的数字摘要。但这两个算法的安全强度比较低，不够安全，在 TLS 里已经被禁止使用了。
  
  目前 TLS 推荐使用的是 SHA-1 的后继者：SHA-2。
  
  SHA-2 实际上是一系列摘要算法的统称，总共有 6 种，常用的有 SHA224、SHA256、SHA384，分别能够生成 28 字节、32 字节、48 字节的摘要。
  

- 完整性
- 数字签名
- 数字证书和 CA
- HTTPS 建立连接
- TLS 协议的组成

	- 记录协议（Record Protocol）规定了 TLS 收发数据的基本单位：记录（record）。它有点像是 TCP 里的 segment，所有的其他子协议都需要通过记录协议发出。但多个记录数据可以在一个 TCP 包里一次性发出，也并不需要像 TCP 那样返回 ACK。
	- 警报协议（Alert Protocol）的职责是向对方发出警报信息，有点像是 HTTP 协议里的状态码。比如，protocol_version 就是不支持旧版本，bad_certificate 就是证书有问题，收到警报后另一方可以选择继续，也可以立即终止连接。
	- 握手协议（Handshake Protocol）是 TLS 里最复杂的子协议，要比 TCP 的 SYN/ACK 复杂的多，浏览器和服务器会在握手过程中协商 TLS 版本号、随机数、密码套件等信息，然后交换证书和密钥参数，最终双方协商得到会话密钥，用于后续的混合加密系统。
	- 最后一个是变更密码规范协议（Change Cipher Spec Protocol），它非常简单，就是一个“通知”，告诉对方，后续的数据都将使用加密保护。那么反过来，在它之前，数据都是明文的。

- CDHE 握手过程
- RSA 握手过程
- 双向认证

### 面渣逆袭系列
（微信公众号：三分恶）

- 1. 面渣逆袭：Java基础五十三问，快来看看有没有你不会的！

	- Java概述

		- 1.什么是Java？
		- 2.Java语言有哪些特点？
		- 3.JVM、JDK 和 JRE 有什么区别？
		- 4.说说什么是跨平台性？原理是什么
		- 5.什么是字节码？采用字节码的好处是什么?
		- 6.为什么说 Java 语言“编译与解释并存”？

	- 基础语法

		- 7.Java有哪些数据类型？
		- 8.自动类型转换、强制类型转换？看看这几行代码？
		- 9.什么是自动拆箱/封箱？
		- 10.&和&&有什么区别？
		- 11.switch 是否能作用在 byte/long/String上？
		- 12.break ,continue ,return 的区别及作用？
		- 13.用最有效率的方法计算2乘以8？
		- 14.说说自增自减运算？看下这几个代码运行结果？

	- 面向对象

		- 15.⾯向对象和⾯向过程的区别?
		- 17.重载（overload）和重写（override）的区别？
		- 18.访问修饰符public、private、protected、以及不写（默认）时的区别？
		- 19.this关键字有什么作用？
		- 20.抽象类(abstract class)和接口(interface)有什么区别？
		- 21.成员变量与局部变量的区别有哪些？
		- 22.静态变量和实例变量的区别？静态方法、实例方法呢？
		- 24.final关键字有什么作用？
		- 25.final、finally、finalize的区别？
		- 26.==和 equals 的区别？
		- 27.hashCode与 equals?
		- 28.Java是值传递，还是引用传递？
		- 29.深拷贝和浅拷贝?
		- 30.Java 创建对象有哪几种方式？

	- 常用类

		- 31.String 是 Java 基本数据类型吗？可以被继承吗？
		- 32.String和StringBuilder、StringBuffer的区别？
		- 34.String不是不可变类吗？字符串拼接是如何实现的？
		- 35.intern方法有什么作用？
		- 36.Integer a= 127，Integer b = 127；Integer c= 128，Integer d = 128；，相等吗?
		- 37.String怎么转成Integer的？原理？
		- 38.Object 类的常见方法?

	- 异常处理

		- 39.Java 中异常处理体系?
		- 40.异常的处理方式？
		- 41.三道经典异常处理代码题

	- I/O

		- 42.Java 中 IO 流分为几种?
		- 43.既然有了字节流,为什么还要有字符流?
		- 44.BIO、NIO、AIO？

	- 序列化

		- 45.什么是序列化？什么是反序列化？
		- 46.说说有几种序列化方式？

	- 泛型

		- 47.Java 泛型了解么？什么是类型擦除？介绍一下常用的通配符？

	- 注解

		- 48.说一下你对注解的理解？

	- 反射

		- 49.什么是反射？应用？原理？

	- JDK1.8新特性

		- 50.JDK1.8都有哪些新特性？
		- 51.Lambda 表达式了解多少？
		- 52.Optional了解吗？
		- 53.Stream 流用过吗？

- 2. 面渣逆袭：Java集合连环三十问

	- 引言

		- 1.说说有哪些常见集合？
		- 2.ArrayList和LinkedList有什么区别？
		- 3.ArrayList的扩容机制了解吗？

- 3. 面渣逆袭：Java并发六十问，图文详解，快来看看你会多少道！

- 4. 面渣逆袭：线程池夺命连环十八问

- 5. 面渣逆袭：JVM经典五十问，这下面试稳了！

- 6. 面渣逆袭：Spring三十五问，四万字+五十图详解！建议收藏！

- 7. 面渣逆袭：二十二图、八千字、二十问，彻底搞定MyBatis！

- 8. 面渣逆袭：Redis连环五十二问！三万字+八十图详解！

- 9. 面渣逆袭：RocketMQ二十三问

*XMind - Trial Version*